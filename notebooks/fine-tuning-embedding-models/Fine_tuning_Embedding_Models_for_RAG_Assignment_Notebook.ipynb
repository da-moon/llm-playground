{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckbbj5diaHkg"
      },
      "source": [
        "# Fine-tuning Embeddings for RAG on Specific Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xwor_3X6ODX"
      },
      "source": [
        "#### Basic Overview of Fine-tuning Embeddings\n",
        "\n",
        "In essence, what we want to do when we fine-tune our embedding models is very simple:\n",
        "\n",
        "```\n",
        "Move the embeddings for questions relating to a document\n",
        "closer together with that document\n",
        "```\n",
        "\n",
        "We can think of fine-tuning our embedding models as follows:\n",
        "\n",
        "1) We have some pair of text items that *should* be closer together\n",
        "  - `Question`, `Document` pairs\n",
        "  - EX: `Who drives the bus?`, `The bus was driven by Kyle, the Bus Driver`.\n",
        "\n",
        "2) We use these pairs as labeled data to fine-tune our embedding model.\n",
        "\n",
        "The process of training helps the model more accurately associate our questions with the correct documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX5R3HVz6FOQ"
      },
      "source": [
        "#####â“ Question #1:\n",
        "\n",
        "Describe the nuance between using Q&D pairs to train the embedding model vs. inter-document pairs/related sentences.\n",
        "\n",
        "What caveats does this approach have? Are there any special considerations for what kind of Q's we should use?\n",
        "\n",
        "---\n",
        "\n",
        "**ANSWER:**\n",
        "\n",
        "We are specifically relating *the questions* to *the documents*. This means that we are making our embedding model at the very specific task of relating potential questions to specific documents.\n",
        "\n",
        "There are many caveats, but the main ones are:\n",
        "\n",
        "- Your Q's should reflect the Q's of your users\n",
        "- This kind of fine-tuning will (purposefully) \"overfit\" on your data; this is the desired result in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ðŸ”Answer #1:\n",
        "\n",
        "\n",
        "The nuance between using Question & Document (Q&D) pairs vs. inter-document pairs/related sentences to train an embedding model lies in the specific task and goal of the fine-tuning:\n",
        "\n",
        "##### Q&D pairs:\n",
        "\n",
        "- This approach specifically trains the model to relate potential user questions to relevant documents.\n",
        "- It optimizes the model for the task of retrieving documents based on natural language queries.\n",
        "- The model learns to map questions and their corresponding relevant documents closer together in the embedding space.\n",
        "\n",
        "##### Inter-document pairs/related sentences:\n",
        "- This approach trains the model on relationships between different parts of the corpus itself.\n",
        "- It helps the model understand the overall structure and connections within the document set.\n",
        "- The model learns to represent similar or related content closer together, regardless of how it might be queried.\n",
        "\n",
        "##### Key caveats and considerations:\n",
        "\n",
        "1. Overfitting: Fine-tuning on Q&D pairs will intentionally \"overfit\" the model to the specific corpus and question types. This is actually desired for a targeted retrieval system, but may reduce generalizability.\n",
        "\n",
        "2. Question quality: The questions used should reflect real user queries as closely as possible. Using artificially generated or overly simplistic questions may not translate well to real-world performance.\n",
        "\n",
        "3. Coverage: Ensure the Q&D pairs cover a wide range of topics and query types within the corpus to avoid blind spots.\n",
        "\n",
        "4. Bias: Be aware that the choice of questions can introduce biases in how the model interprets and retrieves information.\n",
        "\n",
        "5. Evaluation: It's crucial to evaluate the fine-tuned model on a separate test set to ensure it generalizes well to unseen questions.\n",
        "\n",
        "6. Maintenance: As the corpus or typical user questions evolve, the model may need to be periodically re-fine-tuned to maintain performance.\n",
        "\n",
        "7. Complementary approaches: In some cases, a combination of Q&D fine-tuning and inter-document relationship training might provide the best overall performance.\n",
        "\n",
        "8. Domain specificity: Q&D fine-tuning is particularly valuable for domain-specific applications where the vocabulary and concepts might be very different from general language.\n",
        "\n",
        "##### Summary\n",
        "\n",
        "By focusing on Q&D pairs, the embedding model becomes highly specialized for the\n",
        "task of retrieving relevant documents based on user queries (Overfitted to the training data) , which is\n",
        "particularly useful for building effective retrieval augmented generation (RAG)\n",
        "systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NkSaurzbpyS"
      },
      "source": [
        "## Task 1: Dependencies and Boilerplate\n",
        "\n",
        "We'll set up our `nest_asyncio` so we can leverage async loops in our Notebook.\n",
        "\n",
        "We'll also install the required libraries we'll be using today, and set up our OpenAI API key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is remote kernel: True\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "# FIXME\n",
        "# def is_remote_kernel() -> bool:\n",
        "#     import ipykernel\n",
        "#     connection_file = ipykernel.get_connection_file()\n",
        "#     kernel_ip = connection_file.split('-')[1].split('.')[0]\n",
        "#     local_ip = socket.gethostbyname(socket.gethostname())\n",
        "#     return kernel_ip != local_ip\n",
        "def is_remote_kernel() -> bool:\n",
        "    local_ip = socket.gethostbyname(socket.gethostname())\n",
        "    return local_ip != \"127.0.1.1\"\n",
        "\n",
        "print(f\"Is remote kernel: {is_remote_kernel()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jupyter_black\n",
        "\n",
        "jupyter_black.load(line_length=88, target_version=\"py39\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from loguru import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c_EUibmcDU3"
      },
      "source": [
        "### Nest Asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zq-6s7LbPnKH"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FM-eUlrcI8a"
      },
      "source": [
        "### Provide OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_mlurVqtrp",
        "outputId": "058d7351-e127-4245-b181-5ab62a6ea019"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFZ217gCDVTr"
      },
      "source": [
        "## Task 2: Loading Data\n",
        "\n",
        "We'll be using a recent document released by the EU 'laying down harmonised rules on artificial intelligence and amending Regulations'.\n",
        "\n",
        "The data can be found\n",
        "[here](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32024R1689),\n",
        "though we will be using a HTML version which was collected into the AIM\n",
        "DataRepository.\n",
        "\n",
        "<!-- TODO: ADD a summary of subtasks -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2 : Cloning the Data Repository\n",
        "\n",
        "We need to clone the source data repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "from git import Repo\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from typing import Optional,Tuple\n",
        "\n",
        "\n",
        "class RepoManager:\n",
        "    \"\"\"\n",
        "    Manages cloning of Git repositories with progress indication.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def clone_repo_with_progress(\n",
        "        repo_url: str, clone_path: Optional[str] = None\n",
        "    ) -> Tuple[Repo, str]:\n",
        "        if clone_path is None:\n",
        "            temp_dir = tempfile.TemporaryDirectory()\n",
        "            clone_path = temp_dir.name\n",
        "        os.makedirs(os.path.dirname(clone_path), exist_ok=True)\n",
        "        pbar = tqdm_notebook(unit=\"B\", unit_scale=True, desc=\"Cloning\")\n",
        "\n",
        "        def progress(op_code, cur_count, max_count=None, message=\"\"):\n",
        "            pbar.total = max_count\n",
        "            pbar.update(cur_count - pbar.n)\n",
        "\n",
        "        repo: Repo = Repo.clone_from(\n",
        "            url=repo_url, to_path=clone_path, progress=progress\n",
        "        )\n",
        "        pbar.close()\n",
        "        return repo, clone_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "repo_root_path = Path(os.getcwd()).joinpath(\"DataRepository\")\n",
        "\n",
        "if not is_remote_kernel():\n",
        "    temp_dir = tempfile.TemporaryDirectory()\n",
        "    repo_root_path = Path(temp_dir.name).resolve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:23:26.460\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1mRepository already has already been cloned.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:23:26.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mRepository cloned to: /notebooks/DataRepository\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "repo_url = \"https://github.com/AI-Maker-Space/DataRepository.git\"\n",
        "if not repo_root_path.joinpath(\".git\").exists():\n",
        "    RepoManager.clone_repo_with_progress(\n",
        "            repo_url=repo_url, clone_path=str(repo_root_path)\n",
        "    )\n",
        "else:\n",
        "    logger.debug(f\"Repository already has already been cloned.\")\n",
        "logger.info(f\"Repository cloned to: {str(repo_root_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr3uSmKQPAWG",
        "outputId": "5ab32ed1-a07c-4d97-d320-b615cedf5979"
      },
      "outputs": [],
      "source": [
        "# %cd DataRepository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2 : Document Processor Class\n",
        "We will be loading HTML documents , splitting them into chunks and converting\n",
        "them into `langchain_core.documents.Document` objects. \n",
        "\n",
        "As this is a process that can happen repeatedly, we will be creating a class to\n",
        "handle this so that we adhere to best practices and good coding form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "from typing import List, Optional\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from loguru import logger\n",
        "\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"\n",
        "    Processes documents: loads, splits, and assigns unique IDs.\n",
        "    \"\"\"\n",
        "    @logger.catch\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_path: str,\n",
        "        chunk_size: int = 750,\n",
        "        chunk_overlap: int = 20,\n",
        "    ) -> None:\n",
        "        self.file_path = Path(file_path).resolve()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.documents: Optional[List[Document]] = None\n",
        "        self._sanity_check()\n",
        "        self._init_loader()\n",
        "        self._init_splitter()\n",
        "    @logger.catch\n",
        "    def _sanity_check(self) -> None:\n",
        "        if not isinstance(self.chunk_size, int) or self.chunk_size <= 0:\n",
        "            raise ValueError(\"chunk_size must be a positive integer\")\n",
        "        if not isinstance(self.chunk_overlap, int) or self.chunk_overlap < 0:\n",
        "            raise ValueError(\"chunk_overlap must be a non-negative integer\")\n",
        "        if not self.file_path.exists():\n",
        "            raise FileNotFoundError(f\"File not found: {str(self.file_path)}\")\n",
        "    @logger.catch\n",
        "    def _init_loader(self) -> None:\n",
        "        self.loader = UnstructuredHTMLLoader(str(self.file_path))\n",
        "    @logger.catch\n",
        "    def _init_splitter(self) -> None:\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=self.chunk_size,\n",
        "            chunk_overlap=self.chunk_overlap,\n",
        "            length_function=len,\n",
        "        )\n",
        "    @logger.catch\n",
        "    def load_documents(self) -> List[Document]:\n",
        "        if self.documents is None:\n",
        "            self.documents = self.loader.load()\n",
        "        return self.documents\n",
        "    @logger.catch\n",
        "    def split_documents(self) -> List[Document]:\n",
        "        if self.documents is None:\n",
        "            self.load_documents()\n",
        "        if not self.documents:\n",
        "            raise ValueError(\"No documents loaded to split\")\n",
        "        split_docs: List[Document] = self.text_splitter.split_documents(self.documents)\n",
        "        return split_docs\n",
        "    @logger.catch\n",
        "    def assign_unique_ids(self, documents: List[Document]) -> List[Document]:\n",
        "        if not documents:\n",
        "            raise ValueError(\"Input document list is empty\")\n",
        "        id_set = set()\n",
        "        for document in documents:\n",
        "            new_id = str(uuid.uuid4())\n",
        "            while new_id in id_set:\n",
        "                new_id = str(uuid.uuid4())\n",
        "            id_set.add(new_id)\n",
        "            document.metadata[\"id\"] = new_id\n",
        "        return documents\n",
        "    @logger.catch\n",
        "    def process(self) -> List[Document]:\n",
        "        split_docs = self.split_documents()\n",
        "        processed_docs = self.assign_unique_ids(split_docs)\n",
        "        return processed_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-owwr1U0W1q"
      },
      "source": [
        "### Task 2 : Loading the EU AI Act Document\n",
        "\n",
        "Next we're going to be using the `UnstructuredHTMLLoader` to load our HTML document into a LangChain document using the [Unstructured](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.html.UnstructuredHTMLLoader.html) library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DHJhTzsvN75t"
      },
      "outputs": [],
      "source": [
        "html_path :Path = repo_root_path.joinpath(\"eu_ai_act.html\")\n",
        "processor = DocumentProcessor(f\"{str(html_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UbKa6-V0nvp"
      },
      "source": [
        "<!-- Next, we'll set up a classic naive chunking strategy as we only care that the documents get parsed into chunks that we can generate synthetic questions about. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NsPrOOqXOsNX"
      },
      "outputs": [],
      "source": [
        "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size = 750,\n",
        "#     chunk_overlap  = 20,\n",
        "#     length_function = len\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OMYPX6N6Os8M"
      },
      "outputs": [],
      "source": [
        "# training_documents = text_splitter.split_documents(training_documents_loaded.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AwyIForybIpo"
      },
      "outputs": [],
      "source": [
        "# import uuid\n",
        "\n",
        "# id_set = set()\n",
        "\n",
        "# for document in training_documents:\n",
        "#   id = str(uuid.uuid4())\n",
        "#   while id in id_set:\n",
        "#     id = uuid.uuid4()\n",
        "#   id_set.add(id)\n",
        "#   document.metadata[\"id\"] = id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proces the documents and load them Next we can load/split these documents as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_documents:List[Document] = processor.process()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJnL4oNg341U"
      },
      "source": [
        "Next, we'll simply use naive Python slicing to create a training, test, and\n",
        "validation set to prepare our data for the next step.\n",
        "The following class helps with generating randomized splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "from langchain_core.documents import Document\n",
        "from loguru import logger\n",
        "\n",
        "\n",
        "class DocumentMixer:\n",
        "    \"\"\"\n",
        "    Splits documents into training, validation, and test sets.\n",
        "    \"\"\"\n",
        "\n",
        "    @logger.catch\n",
        "    def __init__(\n",
        "        self,\n",
        "        documents: List[Document],\n",
        "        train_ratio: Optional[float] = None,\n",
        "        val_ratio: Optional[float] = None,\n",
        "        test_ratio: Optional[float] = None,\n",
        "        train_size: Optional[int] = None,\n",
        "        val_size: Optional[int] = None,\n",
        "        test_size: Optional[int] = None,\n",
        "    ) -> None:\n",
        "        if not documents:\n",
        "            raise ValueError(\"The document list cannot be empty\")\n",
        "        self.documents = documents.copy()\n",
        "        random.shuffle(self.documents)\n",
        "        total_docs = len(documents)\n",
        "\n",
        "        if train_size is not None and val_size is not None and test_size is not None:\n",
        "            if train_size + val_size + test_size > total_docs:\n",
        "                raise ValueError(\n",
        "                    \"Sum of train_size, val_size, and test_size exceeds total documents\"\n",
        "                )\n",
        "            self.train_size = train_size\n",
        "            self.val_size = val_size\n",
        "            self.test_size = test_size\n",
        "        elif (\n",
        "            train_ratio is not None and val_ratio is not None and test_ratio is not None\n",
        "        ):\n",
        "            if not math.isclose(\n",
        "                train_ratio + val_ratio + test_ratio, 1.0, rel_tol=1e-9\n",
        "            ):\n",
        "                raise ValueError(\"Train, validation, and test ratios must sum to 1\")\n",
        "            self.train_size = int(total_docs * train_ratio)\n",
        "            self.val_size = int(total_docs * val_ratio)\n",
        "            self.test_size = total_docs - self.train_size - self.val_size\n",
        "        else:\n",
        "            raise ValueError(\"Either sizes or ratios must be provided for splitting\")\n",
        "\n",
        "    @logger.catch\n",
        "    def get_train_docs(self) -> List[Document]:\n",
        "        return self.documents[: self.train_size]\n",
        "\n",
        "    @logger.catch\n",
        "    def get_val_docs(self) -> List[Document]:\n",
        "        return self.documents[self.train_size : self.train_size + self.val_size]\n",
        "\n",
        "    @logger.catch\n",
        "    def get_test_docs(self) -> List[Document]:\n",
        "        return self.documents[\n",
        "            self.train_size\n",
        "            + self.val_size : self.train_size\n",
        "            + self.val_size\n",
        "            + self.test_size\n",
        "        ]\n",
        "    @logger.catch\n",
        "    def get_all_splits(self) -> Tuple[List[Document], List[Document], List[Document]]:\n",
        "        train_docs: List[Document] = self.get_train_docs()\n",
        "        val_docs: List[Document] = self.get_val_docs()\n",
        "        test_docs: List[Document] = self.get_test_docs()\n",
        "        return train_docs, val_docs, test_docs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will create the mixer and generate the splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mixer = DocumentMixer(documents=training_documents,train_ratio = 0.7,\n",
        "# val_ratio = 0.15, test_ratio=0.15)\n",
        "\n",
        "# mixer = DocumentMixer(\n",
        "#     documents=training_documents,\n",
        "#     train_size=300,\n",
        "#     val_size=50,\n",
        "#     test_size=50,\n",
        "# )\n",
        "mixer = DocumentMixer(\n",
        "    documents=training_documents, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MTS4GTSEcnG4"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.documents.base import Document\n",
        "\n",
        "training_split_documents  = mixer.get_train_docs()\n",
        "val_split_documents = mixer.get_val_docs()\n",
        "test_split_documents = mixer.get_test_docs()\n",
        "\n",
        "# training_split_documents: list[Document] = training_documents[:300]\n",
        "# val_split_documents = training_documents[300:350]\n",
        "# test_split_documents = training_documents[350:400]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzlvKbONDWvQ"
      },
      "source": [
        "## Task 3: Constructing a Fine-tuning Dataset\n",
        "\n",
        "Using the nodes we created above, we can finally start constructing a fine-tuning dataset utilizing OpenAI's `gpt-4o-mini` (released [July 18th](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)).\n",
        "\n",
        "The basic idea here is straightforward enough:\n",
        "\n",
        "1. We look at a document\n",
        "2. We generate questions that could be answered by that node\n",
        "\n",
        "This gives us a number of question/context pairs that we can use to fine-tune our Embeddings model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_EWfmIscMrvg"
      },
      "outputs": [],
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# qa_chat_model = ChatOpenAI(\n",
        "#     model=\"gpt-4o-mini\",\n",
        "#     temperature=0\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-hLnsSB6Y-S"
      },
      "source": [
        "We'll create a simple Question Generation prompt to query `gpt-4o-mini` to generate Questions for each retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "diEWcw00NMSj"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# qa_prompt = \"\"\"\\\n",
        "# Given the following context, you must generate questions based on only the provided context.\n",
        "\n",
        "# You are to generate {n_questions} questions which should be provided in the following format:\n",
        "\n",
        "# 1. QUESTION #1\n",
        "# 2. QUESTION #2\n",
        "# ...\n",
        "\n",
        "# Context:\n",
        "# {context}\n",
        "# \"\"\"\n",
        "\n",
        "# qa_prompt_template = ChatPromptTemplate.from_template(qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u87Izpgm6_fk"
      },
      "source": [
        "We'll create a simple chain to query the LLM!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ggl9SSjiNbpG"
      },
      "outputs": [],
      "source": [
        "# question_generation_chain = qa_prompt_template | qa_chat_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4duvHirh7DQv"
      },
      "source": [
        "There's a lot going on in this function - let's take a deeper look:\n",
        "\n",
        "1. First, we provide a list of documents and a number of questions\n",
        "2. We, for each document in our list, generate `n_questions` of questions.\n",
        "3. We then associate those questions and contexts via a `UUID`.\n",
        "\n",
        "> NOTE: The reason we're doing this `UUID` association is for ease of use later in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lm2JvgC9X37"
      },
      "source": [
        "##### ðŸ—ï¸ Activity #1:\n",
        "\n",
        "We have:\n",
        "\n",
        "- Lists of `Documents` with the `metadata` field `id`.\n",
        "\n",
        "We need:\n",
        "\n",
        "- An object with key `id`, which have values `str` questions.\n",
        "- An object with key `question_id`, which have values `List(str)` which will be a list of associated `context_id`.\n",
        "\n",
        "An Example:\n",
        "\n",
        "question_object:\n",
        "```python\n",
        "{\n",
        "'b4b95fb6-f827-4454-aa5b-20e62733f172': 'What types of accessible formats are available for persons with disabilities?',\n",
        "'df58ee4f-714c-419e-8324-94e5870574e2': 'How do accessible formats benefit persons with disabilities?',\n",
        "'505fce8b-0e56-48de-a251-61027e396918': 'What are some of the risks associated with the increasing capabilities of AI systems that generate synthetic content?',\n",
        "'8ff0ab33-60dc-4fee-8958-91bfb686aca8': 'Why is it important for providers of AI systems to embed technical solutions for marking and detecting synthetic content?'\n",
        "}\n",
        " ```\n",
        "\n",
        " context_object:\n",
        " ```python\n",
        "{\n",
        "'b4b95fb6-f827-4454-aa5b-20e62733f172': ['dd75bf94-75f3-4603-8e4b-5522f6925638'],\n",
        "'df58ee4f-714c-419e-8324-94e5870574e2': ['dd75bf94-75f3-4603-8e4b-5522f6925638'],\n",
        "'505fce8b-0e56-48de-a251-61027e396918': ['ffe3893f-688c-48e8-90bd-7a9feb953d90'],\n",
        "'8ff0ab33-60dc-4fee-8958-91bfb686aca8': ['ffe3893f-688c-48e8-90bd-7a9feb953d90'],\n",
        "}\n",
        " ```\n",
        "\n",
        " As you can see, a piece of context can be associated with more than 1 question.\n",
        "\n",
        " The task is to write the Python function(s) to accomplish this task.\n",
        "\n",
        " Your function signature is provided below, along with the desired return values.\n",
        "\n",
        " > NOTE: You can make any modifications that you desire - assuming that you have the correct input and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "U4yi4NfTCnLc"
      },
      "outputs": [],
      "source": [
        "# import tqdm\n",
        "# import uuid\n",
        "\n",
        "\n",
        "# def create_questions(documents, n_questions):# -> tuple[dict[Any, Any], dict[Any, Any]]:\n",
        "#     questions = {}\n",
        "#     relevant_docs = {}\n",
        "\n",
        "#     for doc in tqdm.tqdm(documents, desc=\"Processing documents\"):\n",
        "#         context = doc.page_content\n",
        "#         doc_id = doc.metadata[\"id\"]\n",
        "\n",
        "#         # Generate questions using the question_generation_chain\n",
        "#         generated_questions = question_generation_chain.invoke(\n",
        "#             {\"context\": context, \"n_questions\": n_questions}\n",
        "#         )\n",
        "\n",
        "#         # Check if generated_questions is a string or a list\n",
        "#         if isinstance(generated_questions.content, str):\n",
        "#             question_list = generated_questions.content.strip().split(\"\\n\")\n",
        "#         elif isinstance(generated_questions.content, list):\n",
        "#             question_list = generated_questions.content\n",
        "#         else:\n",
        "#             raise ValueError(\n",
        "#                 f\"Unexpected type for generated_questions: {type(generated_questions.content)}\"\n",
        "#             )\n",
        "\n",
        "#         for q in question_list:\n",
        "#             # If q is a dict, assume it contains the question\n",
        "#             if isinstance(q, dict):\n",
        "#                 q = q.get(\"question\", \"\")\n",
        "\n",
        "#             # Remove numbering and any leading/trailing whitespace\n",
        "#             q = q.split(\".\", 1)[-1].strip() if isinstance(q, str) else str(q)\n",
        "\n",
        "#             # Generate a unique ID for the question\n",
        "#             question_id = str(uuid.uuid4())\n",
        "\n",
        "#             # Add the question to the questions dictionary\n",
        "#             questions[question_id] = q\n",
        "\n",
        "#             # Add the document ID to the relevant_docs dictionary\n",
        "#             relevant_docs[question_id] = [doc_id]\n",
        "\n",
        "#     return questions, relevant_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we aggregagate question generator logic in the following class and use it\n",
        "instead of using module level functions to follow object-oriented programming principles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import uuid\n",
        "# from typing import List, Dict, Optional, Tuple, Union\n",
        "# from langchain_core.documents import Document\n",
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from tqdm.notebook import tqdm as tqdm_notebook\n",
        "# import concurrent.futures\n",
        "# from datasets import Dataset\n",
        "# from loguru import logger\n",
        "# import json\n",
        "# from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "# class DatasetGenerator:\n",
        "#     def __init__(self, documents: List[Document], model_name: str = \"gpt-4o-mini\"):\n",
        "#         if not documents or not all(isinstance(doc, Document) for doc in documents):\n",
        "#             raise ValueError(\"documents must be a non-empty list of Document objects\")\n",
        "\n",
        "#         self.documents = documents\n",
        "#         self.qa_chat_model = ChatOpenAI(model=model_name, temperature=0)\n",
        "#         self.qa_prompt_template = ChatPromptTemplate.from_template(\n",
        "#             \"\"\"\n",
        "#             Given the following context, generate {n_questions} questions based only on the provided context.\n",
        "#             Format the questions as a numbered list:\n",
        "\n",
        "#             1. QUESTION #1\n",
        "#             2. QUESTION #2\n",
        "#             ...\n",
        "\n",
        "#             Context:\n",
        "#             {context}\n",
        "#             \"\"\"\n",
        "#         )\n",
        "#         self.questions: Dict[str, str] = {}\n",
        "#         self.relevant_contexts: Dict[str, List[str]] = {}\n",
        "#         self.corpus: Dict[str, str] = {}\n",
        "#         self._dataset_cache: Optional[Dataset] = None\n",
        "#         self._processed: bool = False\n",
        "#         logger.info(\n",
        "#             f\"DatasetGenerator initialized with {len(documents)} documents and model {model_name}\"\n",
        "#         )\n",
        "\n",
        "#     def process(\n",
        "#         self,\n",
        "#         n_questions: int = 2,\n",
        "#         max_workers: Optional[int] = None,\n",
        "#     ) -> None:\n",
        "#         if self._processed:\n",
        "#             logger.info(\"Dataset already processed. Returning without reprocessing.\")\n",
        "#             return\n",
        "\n",
        "#         logger.info(f\"Processing dataset with {n_questions} questions per document\")\n",
        "\n",
        "#         self._generate_corpus()\n",
        "#         self._generate_questions(n_questions, max_workers)\n",
        "#         self._generate_relevant_contexts()\n",
        "\n",
        "#         self._processed = True\n",
        "#         logger.info(\n",
        "#             f\"Processed dataset with {len(self.questions)} questions and {len(self.corpus)} documents\"\n",
        "#         )\n",
        "\n",
        "#     def _generate_corpus(self) -> None:\n",
        "#         logger.info(\"Generating corpus\")\n",
        "#         self.corpus = {doc.metadata[\"id\"]: doc.page_content for doc in self.documents}\n",
        "#         logger.debug(f\"Generated corpus with {len(self.corpus)} documents\")\n",
        "\n",
        "#     def _generate_questions(\n",
        "#         self, n_questions: int, max_workers: Optional[int],\n",
        "#     ) -> None:\n",
        "#         logger.info(f\"Generating questions with {n_questions} questions per document\")\n",
        "#         self.questions.clear()\n",
        "\n",
        "#         if max_workers is not None:\n",
        "#             logger.info(\"Running LLM queries in parallel\")\n",
        "#             with concurrent.futures.ThreadPoolExecutor(\n",
        "#                 max_workers=max_workers\n",
        "#             ) as executor:\n",
        "#                 list(\n",
        "#                     tqdm_notebook(\n",
        "#                         executor.map(\n",
        "#                             lambda doc: self._process_single_document(doc, n_questions),\n",
        "#                             self.documents,\n",
        "#                         ),\n",
        "#                         total=len(self.documents),\n",
        "#                         desc=\"Processing documents\",\n",
        "#                     )\n",
        "#                 )\n",
        "#         else:\n",
        "#             logger.info(\"Running LLM queries sequentially\")\n",
        "#             for doc in tqdm_notebook(self.documents, desc=\"Processing documents\"):\n",
        "#                 self._process_single_document(doc, n_questions)\n",
        "\n",
        "#     def _process_single_document(self, doc: Document, n_questions: int) -> None:\n",
        "#         doc_questions, doc_id = self._process_document(doc, n_questions)\n",
        "#         for question in doc_questions:\n",
        "#             question_id = str(uuid.uuid4())\n",
        "#             self.questions[question_id] = question\n",
        "#             logger.trace(f\"Generated question: {question} for document {doc_id}\")\n",
        "\n",
        "#     def _generate_relevant_contexts(self) -> None:\n",
        "#         logger.info(\"Generating relevant contexts\")\n",
        "#         self.relevant_contexts = {\n",
        "#             q_id: [doc.metadata[\"id\"]]\n",
        "#             for doc in self.documents\n",
        "#             for q_id in self.questions\n",
        "#         }\n",
        "#         logger.debug(\n",
        "#             f\"Generated relevant contexts for {len(self.relevant_contexts)} questions\"\n",
        "#         )\n",
        "\n",
        "#     def _process_document(\n",
        "#         self, doc: Document, n_questions: int\n",
        "#     ) -> Tuple[List[str], str]:\n",
        "#         context = doc.page_content\n",
        "#         doc_id = doc.metadata[\"id\"]\n",
        "#         generated_questions: BaseMessage = self.qa_chat_model.invoke(\n",
        "#             self.qa_prompt_template.format(context=context, n_questions=n_questions)\n",
        "#         )\n",
        "#         processed_questions = self._process_model_output(\n",
        "#             generated_questions.content, n_questions\n",
        "#         )\n",
        "#         logger.trace(\n",
        "#             f\"Generated {len(processed_questions)} questions for document {doc_id}\"\n",
        "#         )\n",
        "#         return processed_questions, doc_id\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _process_model_output(\n",
        "#         content: Union[str, List[Union[str, Dict]]], n_questions: int\n",
        "#     ) -> List[str]:\n",
        "#         processed_questions = []\n",
        "#         if isinstance(content, str):\n",
        "#             questions = content.strip().split(\"\\n\")\n",
        "#         elif isinstance(content, list):\n",
        "#             questions = content\n",
        "#         else:\n",
        "#             raise ValueError(f\"Unexpected content type: {type(content)}\")\n",
        "\n",
        "#         for q in questions:\n",
        "#             if isinstance(q, dict):\n",
        "#                 q = q.get(\"question\", \"\")\n",
        "#             if isinstance(q, str):\n",
        "#                 q = q.split(\".\", 1)[-1].strip()\n",
        "#                 if q:\n",
        "#                     processed_questions.append(q)\n",
        "\n",
        "#         if len(processed_questions) != n_questions:\n",
        "#             logger.warning(\n",
        "#                 f\"Expected {n_questions} questions, but got {len(processed_questions)}\"\n",
        "#             )\n",
        "\n",
        "#         return processed_questions\n",
        "\n",
        "#     def get_dataset(self) -> Dataset:\n",
        "#         if not self._processed:\n",
        "#             raise ValueError(\"Dataset has not been processed. Call process() first.\")\n",
        "        \n",
        "#         logger.info(\"Creating Dataset object\")\n",
        "#         try:\n",
        "#             if self._dataset_cache is None:\n",
        "#                 questions = list(self.questions.values())\n",
        "#                 relevant_contexts = list(self.relevant_contexts.values())\n",
        "#                 corpus_texts = list(self.corpus.values())\n",
        "#                 corpus_ids = list(self.corpus.keys())\n",
        "\n",
        "#                 # Ensure all lists have the same length\n",
        "#                 n_questions = len(questions)\n",
        "#                 n_docs = len(corpus_texts)\n",
        "\n",
        "#                 if n_questions > n_docs:\n",
        "#                     logger.warning(f\"More questions ({n_questions}) than documents ({n_docs}). Truncating questions.\")\n",
        "#                     questions = questions[:n_docs]\n",
        "#                     relevant_contexts = relevant_contexts[:n_docs]\n",
        "#                 elif n_questions < n_docs:\n",
        "#                     logger.warning(f\"Fewer questions ({n_questions}) than documents ({n_docs}). Padding with empty strings.\")\n",
        "#                     questions.extend([\"\"] * (n_docs - n_questions))\n",
        "#                     relevant_contexts.extend([[] for _ in range(n_docs - n_questions)])\n",
        "#                 self._dataset_cache = Dataset.from_dict({\n",
        "#                     \"questions\": questions,\n",
        "#                     \"relevant_contexts\": relevant_contexts,\n",
        "#                     \"corpus\": corpus_texts,\n",
        "#                     \"doc_id\": corpus_ids\n",
        "#                 })\n",
        "            \n",
        "#             if self._dataset_cache is not None:\n",
        "#                 logger.debug(f\"Returning Dataset with {len(self._dataset_cache)} entries\")\n",
        "#             else:\n",
        "#                 logger.warning(\"Dataset cache is None, returning empty Dataset\")\n",
        "#                 return Dataset.from_dict({\"questions\": [], \"relevant_contexts\": [], \"corpus\": [], \"doc_id\": []})\n",
        "            \n",
        "#             return self._dataset_cache\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Failed to create Dataset: {str(e)}\")\n",
        "#             raise\n",
        "#     def get_corpus(self) -> Dict[str, str]:\n",
        "#         if not self._processed:\n",
        "#             raise ValueError(\"Dataset has not been processed. Call process() first.\")\n",
        "#         return self.corpus\n",
        "\n",
        "#     def get_questions(self) -> Dict[str, str]:\n",
        "#         if not self._processed:\n",
        "#             raise ValueError(\"Dataset has not been processed. Call process() first.\")\n",
        "#         return self.questions\n",
        "\n",
        "#     def get_relevant_contexts(self) -> Dict[str, List[str]]:\n",
        "#         if not self._processed:\n",
        "#             raise ValueError(\"Dataset has not been processed. Call process() first.\")\n",
        "#         return self.relevant_contexts\n",
        "\n",
        "#     def clear(self) -> None:\n",
        "#         logger.info(\"Clearing all processed data\")\n",
        "#         self.questions.clear()\n",
        "#         self.relevant_contexts.clear()\n",
        "#         self.corpus.clear()\n",
        "#         self._dataset_cache = None\n",
        "#         self._processed = False\n",
        "\n",
        "#     def save_dataset_to_json(self, file_path: str) -> None:\n",
        "#         if not self._processed:\n",
        "#             raise ValueError(\"Dataset has not been processed. Call process() first.\")\n",
        "\n",
        "#         logger.info(f\"Saving dataset to {file_path}\")\n",
        "#         try:\n",
        "#             data_dict = {\n",
        "#                 \"questions\": self.questions,\n",
        "#                 \"relevant_contexts\": self.relevant_contexts,\n",
        "#                 \"corpus\": self.corpus,\n",
        "#             }\n",
        "#             with open(file_path, \"w\") as f:\n",
        "#                 json.dump(data_dict, f, indent=4, default=lambda x: x.__dict__, ensure_ascii=False)\n",
        "#             logger.info(f\"Dataset successfully saved to {file_path}\")\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Failed to save dataset to {file_path}: {str(e)}\")\n",
        "#             raise\n",
        "\n",
        "#     def load_dataset_from_json(self, file_path: str) -> None:\n",
        "#         logger.info(f\"Loading dataset from {file_path}\")\n",
        "#         try:\n",
        "#             with open(file_path, \"r\") as f:\n",
        "#                 data_dict = json.load(f)\n",
        "\n",
        "#             self.questions = data_dict[\"questions\"]\n",
        "#             self.relevant_contexts = data_dict[\"relevant_contexts\"]\n",
        "#             self.corpus = data_dict[\"corpus\"]\n",
        "\n",
        "#             self._dataset_cache = None  # Clear cache to force regeneration\n",
        "#             self._processed = True\n",
        "#             logger.info(f\"Dataset successfully loaded from {file_path}\")\n",
        "#         except FileNotFoundError:\n",
        "#             logger.error(f\"File not found: {file_path}\")\n",
        "#             raise\n",
        "#         except json.JSONDecodeError:\n",
        "#             logger.error(f\"Invalid JSON format in file: {file_path}\")\n",
        "#             raise\n",
        "#         except KeyError as e:\n",
        "#             logger.error(f\"Missing key in loaded data: {str(e)}\")\n",
        "#             raise\n",
        "#         except Exception as e:\n",
        "#             logger.error(f\"Unexpected error while loading dataset: {str(e)}\")\n",
        "#             raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Generator, List, Any, TypeAlias\n",
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import InputExample\n",
        "import json\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "# Type aliases\n",
        "QuestionID: TypeAlias = str\n",
        "DocID: TypeAlias = str\n",
        "QuestionText: TypeAlias = str\n",
        "DocText: TypeAlias = str\n",
        "QuestionsDict: TypeAlias = Dict[QuestionID, QuestionText]\n",
        "RelevantContextsDict: TypeAlias = Dict[QuestionID, List[DocID]]\n",
        "CorpusDict: TypeAlias = Dict[DocID, DocText]\n",
        "\n",
        "from loguru import logger\n",
        "class QADataset(TorchDataset):\n",
        "    \"\"\"\n",
        "    Data class for question-answering dataset.\n",
        "    Encapsulates questions, relevant contexts, and corpus.\n",
        "    \"\"\"\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def __init__(\n",
        "        self,\n",
        "        questions: QuestionsDict,\n",
        "        relevant_contexts: RelevantContextsDict,\n",
        "        corpus: CorpusDict,\n",
        "    ):\n",
        "        self.questions: QuestionsDict = questions\n",
        "        self.relevant_contexts: RelevantContextsDict = relevant_contexts\n",
        "        self.corpus: CorpusDict = corpus\n",
        "        self.validate()\n",
        "        self._question_ids: List[QuestionID] = list(self.questions.keys())\n",
        "\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def serialize(self, file_path: str) -> None:\n",
        "        \"\"\"\n",
        "        Serialize the dataset to a JSON file with pretty printing.\n",
        "        \"\"\"\n",
        "        dataset = {\n",
        "            \"questions\": self.questions,\n",
        "            \"relevant_contexts\": self.relevant_contexts,\n",
        "            \"corpus\": self.corpus,\n",
        "        }\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(dataset, f, indent=4, ensure_ascii=False)\n",
        "        logger.info(f\"Dataset serialized to {file_path}\")\n",
        "\n",
        "    @classmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def deserialize(cls, file_path: str) -> 'QADataset':\n",
        "        \"\"\"\n",
        "        Deserialize the dataset from a JSON file.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            dataset = json.load(f)\n",
        "        questions = dataset.get(\"questions\", {})\n",
        "        relevant_contexts = dataset.get(\"relevant_contexts\", {})\n",
        "        corpus = dataset.get(\"corpus\", {})\n",
        "        logger.info(f\"Dataset deserialized from {file_path}\")\n",
        "        instance = cls(questions, relevant_contexts, corpus)\n",
        "        instance.validate()\n",
        "        return instance\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def get_questions(self) -> Dict[str, str]:\n",
        "        return self.questions\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def get_relevant_contexts(self) -> Dict[str, List[str]]:\n",
        "        return self.relevant_contexts\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def get_corpus(self) -> Dict[str, str]:\n",
        "        return self.corpus\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def validate(self) -> None:\n",
        "        \"\"\"\n",
        "        Validate the integrity of the dataset.\n",
        "        \"\"\"\n",
        "        if not self.questions or not self.relevant_contexts or not self.corpus:\n",
        "            raise ValueError(\"Dataset components cannot be empty.\")\n",
        "        if set(self.questions.keys()) != set(self.relevant_contexts.keys()):\n",
        "            raise ValueError(\"Mismatch between questions and relevant contexts.\")\n",
        "        for doc_ids in self.relevant_contexts.values():\n",
        "            for doc_id in doc_ids:\n",
        "                if doc_id not in self.corpus:\n",
        "                    raise ValueError(f\"Document ID {doc_id} in relevant contexts not found in corpus.\")\n",
        "                \n",
        "    @logger.catch(reraise=True)\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._question_ids)\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def __getitem__(self, idx: int) -> InputExample:\n",
        "        \"\"\"\n",
        "        Returns an InputExample containing the question and its corresponding context.\n",
        "        \"\"\"\n",
        "        question_id = self._question_ids[idx]\n",
        "        question_text = self.questions[question_id]\n",
        "        doc_ids:Optional[List[DocID]] = self.relevant_contexts.get(question_id)\n",
        "        if not doc_ids:\n",
        "            raise ValueError(f\"No relevant contexts found for question ID {question_id}\")\n",
        "        doc_id = doc_ids[0]\n",
        "        context:Optional[DocText] = self.corpus.get(doc_id)\n",
        "        if context is None:\n",
        "            raise ValueError(f\"Document ID {doc_id} not found in corpus\")\n",
        "        example = InputExample(texts=[question_text, context])\n",
        "        return example\n",
        "    def __iter__(self) -> Generator[InputExample, Any, None]:\n",
        "        for idx in range(len(self)):\n",
        "            yield self[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "from typing import List, Dict, Union, Any, Optional\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import concurrent.futures\n",
        "from loguru import logger\n",
        "class DatasetGenerator:\n",
        "    \"\"\"\n",
        "    Generates datasets for question-answering tasks from documents.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, documents: List[Document], model_name: str = \"gpt-4o-mini\") -> None:\n",
        "        if not documents or not all(isinstance(doc, Document) for doc in documents):\n",
        "            raise ValueError(\"documents must be a non-empty list of Document objects\")\n",
        "        self.documents: List[Document] = documents\n",
        "        self.qa_chat_model = ChatOpenAI(name=model_name, temperature=0)\n",
        "        self.qa_prompt_template: ChatPromptTemplate = ChatPromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Given the following context, generate {n_questions} questions based only on the provided context.\n",
        "            Format the questions as a numbered list:\n",
        "            1. QUESTION #1\n",
        "            2. QUESTION #2\n",
        "            ...\n",
        "            Context:\n",
        "            {context}\n",
        "            \"\"\"\n",
        "        )\n",
        "        self.questions: Dict[str, str] = {}\n",
        "        self.relevant_contexts: Dict[str, List[str]] = {}\n",
        "        self.corpus: Dict[str, str] = {}\n",
        "        self._question_doc_map: Dict[str, str] = {}\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def generate_dataset(\n",
        "        self, n_questions: int = 2, max_workers: Optional[int] = None\n",
        "    ) -> QADataset:\n",
        "        \"\"\"\n",
        "        Public method to generate the complete dataset.\n",
        "        \"\"\"\n",
        "        self._generate_questions(n_questions, max_workers)\n",
        "        self._generate_relevant_contexts()\n",
        "        self._generate_corpus()\n",
        "        dataset = QADataset(self.questions, self.relevant_contexts, self.corpus)\n",
        "        dataset.validate()\n",
        "        logger.info(\"Dataset generation complete.\")\n",
        "        return dataset\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _generate_questions(\n",
        "        self, n_questions: int = 2, max_workers: Optional[int] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Internal method to generate questions from documents.\n",
        "        \"\"\"\n",
        "        if not self.documents:\n",
        "            raise ValueError(\"No documents provided for question generation.\")\n",
        "        self.questions.clear()\n",
        "        self._question_doc_map.clear()\n",
        "\n",
        "        if max_workers is None or max_workers <= 1:\n",
        "            for doc in tqdm_notebook(self.documents, desc=\"Generating questions\"):\n",
        "                self._process_document(doc, n_questions)\n",
        "        else:\n",
        "            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "                futures = {\n",
        "                    executor.submit(self._process_document, doc, n_questions): doc.metadata[\"id\"]\n",
        "                    for doc in self.documents\n",
        "                }\n",
        "                for future in tqdm_notebook(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Generating questions\"):\n",
        "                    doc_id = futures[future]\n",
        "                    try:\n",
        "                        future.result()\n",
        "                    except Exception as e:\n",
        "                        logger.exception(f\"Error processing document ID {doc_id}: {e}\")\n",
        "                        raise\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _process_document(self, doc: Document, n_questions: int) -> None:\n",
        "        \"\"\"\n",
        "        Internal method to generate questions from a single document.\n",
        "        \"\"\"\n",
        "        context = doc.page_content\n",
        "        doc_id = doc.metadata[\"id\"]\n",
        "        prompt = self.qa_prompt_template.format(context=context, n_questions=n_questions)\n",
        "        generated_questions = self.qa_chat_model.invoke(prompt)\n",
        "        processed_questions = self._process_model_output(\n",
        "            generated_questions.content, n_questions\n",
        "        )\n",
        "        for q in processed_questions:\n",
        "            question_id = str(uuid.uuid4())\n",
        "            self.questions[question_id] = q\n",
        "            self._question_doc_map[question_id] = doc_id\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _process_model_output(\n",
        "        content: Union[str, List[Union[str, Dict[str, str]]]], n_questions: int\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Internal method to process the output from the language model into a list of questions.\n",
        "        \"\"\"\n",
        "        if isinstance(content, str):\n",
        "            processed_questions: List[str] = DatasetGenerator._parse_questions_from_string(content)\n",
        "        elif isinstance(content, list):\n",
        "            processed_questions = DatasetGenerator._parse_questions_from_list(content)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unexpected type for generated_questions content: {type(content)}\"\n",
        "            )\n",
        "        if len(processed_questions) != n_questions:\n",
        "            raise ValueError(\n",
        "                f\"Expected {n_questions} questions, but got {len(processed_questions)}\"\n",
        "            )\n",
        "        return processed_questions\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _parse_questions_from_string(content: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parse questions from a string output.\n",
        "        \"\"\"\n",
        "        lines: List[str] = content.strip().split(\"\\n\")\n",
        "        questions:List[str] = []\n",
        "        for line in lines:\n",
        "            question: Optional[str] = DatasetGenerator._extract_question_from_line(line)\n",
        "            if question:\n",
        "                questions.append(question)\n",
        "        return questions\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _parse_questions_from_list(content_list: List[Union[str, Dict[str, str]]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parse questions from a list output.\n",
        "        \"\"\"\n",
        "        questions:List[str] = []\n",
        "        for item in content_list:\n",
        "            question:Optional[str]  = DatasetGenerator._extract_question_from_item(item)\n",
        "            if question:\n",
        "                questions.append(question)\n",
        "        return questions\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _extract_question_from_line(line: str) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Extract question text from a line of text.\n",
        "        \"\"\"\n",
        "        if line.strip():\n",
        "            question: str = line.split(\".\", 1)[-1].strip()\n",
        "            return question\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _extract_question_from_item(item: Union[str, Dict[str, str]]) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Extract question text from an item in a list.\n",
        "        \"\"\"\n",
        "        if isinstance(item, str):\n",
        "            return DatasetGenerator._extract_question_from_line(item)\n",
        "        elif isinstance(item, dict):\n",
        "            question = item.get(\"question\", \"\").strip()\n",
        "            if question:\n",
        "                return question\n",
        "            else:\n",
        "                raise ValueError(\"Dictionary item missing 'question' key.\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected item type in content list: {type(item)}\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _generate_relevant_contexts(self) -> None:\n",
        "        \"\"\"\n",
        "        Internal method to generate relevant contexts mapping.\n",
        "        \"\"\"\n",
        "        if not self._question_doc_map:\n",
        "            raise ValueError(\"No questions have been generated to map relevant contexts.\")\n",
        "        self.relevant_contexts.clear()\n",
        "        for question_id, doc_id in self._question_doc_map.items():\n",
        "            self.relevant_contexts[question_id] = [doc_id]\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _generate_corpus(self) -> None:\n",
        "        \"\"\"\n",
        "        Internal method to generate the corpus.\n",
        "        \"\"\"\n",
        "        if not self.documents:\n",
        "            raise ValueError(\"No documents available to generate corpus.\")\n",
        "        self.corpus = {doc.metadata[\"id\"]: doc.page_content for doc in self.documents}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FSTG0bb7w73"
      },
      "source": [
        "We'll use the function to generate training, validation, and test data with `n_questions=2` for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "max_workers:Optional[int]=os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Dq6KRqEs0F",
        "outputId": "bf57612e-c2f6-48d3-a6c9-d3ac36b2c3b0"
      },
      "outputs": [],
      "source": [
        "# training_questions, training_relevant_contexts = ### YOUR CODE HERE\n",
        "# training_questions, training_relevant_contexts = create_questions(training_split_documents, n_questions=2)\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "\n",
        "train_generator = DatasetGenerator(training_split_documents)\n",
        "val_generator = DatasetGenerator(val_split_documents)\n",
        "test_generator = DatasetGenerator(test_split_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e2ca427cbb64f7c9ba54cff22295e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating questions:   0%|          | 0/720 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:07.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_dataset\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDataset generation complete.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_dataset: QADataset = train_generator.generate_dataset(n_questions=2,max_workers=max_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:07.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mNumber of training questions: 1440\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:07.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mNumber of documents in training corpus: 720\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:07.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSample question: e4437b49-6f1e-4ae8-b2bc-f873536fca85\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:07.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mRelevant document ID: e7dff837-c329-40a6-be60-d9565405e9ad\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:07.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mSample document content: evidence and the latest developments in technology;...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train_questions: Dict[str, str] = train_dataset.get_questions()\n",
        "logger.info(f\"Number of training questions: {len(train_questions)}\")\n",
        "train_corpus: Dict[str, str] = train_dataset.get_corpus()\n",
        "logger.info(f\"Number of documents in training corpus: {len(train_corpus)}\")\n",
        "train_relevant_contexts = train_dataset.get_relevant_contexts()\n",
        "\n",
        "# Get a sample question and its ID\n",
        "train_sample_question_id, train_sample_question = next(iter(train_questions.items()))\n",
        "logger.info(f\"Sample question: {train_sample_question_id}\")\n",
        "\n",
        "# Get the relevant document ID for this question\n",
        "train_sample_relevant_doc_id = train_relevant_contexts[train_sample_question_id][0]\n",
        "logger.info(f\"Relevant document ID: {train_sample_relevant_doc_id}\")\n",
        "\n",
        "# Optionally, you can also display the content of the relevant document\n",
        "train_sample_doc_content = train_corpus[train_sample_relevant_doc_id]\n",
        "logger.info(f\"Sample document content: {train_sample_doc_content[:100]}...\")  # Display first 100 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZm4CqGVzBx",
        "outputId": "5ef71718-cd33-45bc-b2fa-b8a9ca4650c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a31648c2575c4176abdc39755e7a30b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating questions:   0%|          | 0/154 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:26.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_dataset\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDataset generation complete.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# val_questions, val_relevant_contexts = ### YOUR CODE HERE\n",
        "# val_questions, val_relevant_contexts = create_questions(val_split_documents, n_questions=2)\n",
        "\n",
        "\n",
        "val_dataset: QADataset = val_generator.generate_dataset(n_questions=2,max_workers=max_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:27.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mNumber of training questions: 308\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:27.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mNumber of documents in validation corpus: 154\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:27.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mSample question: fbfa14ee-e783-4549-904e-f2c48faecaa6\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:27.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mRelevant document ID: a2528cf7-9053-495e-be81-dbe64476189d\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:27.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSample document content: to facilitate the providerâ€™s obligation to comply with the requirements of this Regulation, when the...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "val_questions: Dict[str, str] = val_dataset.get_questions()\n",
        "logger.info(f\"Number of training questions: {len(val_questions)}\")\n",
        "val_corpus: Dict[str, str] = val_dataset.get_corpus()\n",
        "logger.info(f\"Number of documents in validation corpus: {len(val_corpus)}\")\n",
        "val_relevant_contexts = val_dataset.get_relevant_contexts()\n",
        "val_sample_question_id, val_sample_question = next(iter(val_questions.items()))\n",
        "logger.info(f\"Sample question: {val_sample_question_id}\")\n",
        "val_sample_relevant_doc_id = val_relevant_contexts[val_sample_question_id][0]\n",
        "logger.info(f\"Relevant document ID: {val_sample_relevant_doc_id}\")\n",
        "val_sample_doc_content = val_corpus[val_sample_relevant_doc_id]\n",
        "logger.info(f\"Sample document content: {val_sample_doc_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "991cc23a7c5e4d03883e579911c1c839",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating questions:   0%|          | 0/155 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:46.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_dataset\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mDataset generation complete.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "test_dataset:QADataset = test_generator.generate_dataset(n_questions=2,max_workers=max_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6qUHg9sV2_y",
        "outputId": "64ea042b-7bb1-4ab7-9710-a1868edf847d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:47.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mNumber of training questions: 310\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mNumber of documents in validation corpus: 155\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mSample question: ee57e704-11a2-494e-a23e-529d91141a5b\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mRelevant document ID: 0647e8da-06dc-418d-a5db-7d51468ae3de\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSample document content: (109) Compliance with the obligations applicable to the providers of general-purpose AI models shoul...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# test_questions, test_relevant_contexts = ### YOUR CODE HERE\n",
        "# test_questions, test_relevant_contexts = create_questions(test_split_documents, n_questions=2)\n",
        "test_questions: Dict[str, str] = test_dataset.get_questions()\n",
        "logger.info(f\"Number of training questions: {len(test_questions)}\")\n",
        "test_corpus: Dict[str, str] = test_dataset.get_corpus()\n",
        "logger.info(f\"Number of documents in validation corpus: {len(test_corpus)}\")\n",
        "test_relevant_contexts = test_dataset.get_relevant_contexts()\n",
        "test_sample_question_id, test_sample_question = next(iter(test_questions.items()))\n",
        "logger.info(f\"Sample question: {test_sample_question_id}\")\n",
        "test_sample_relevant_doc_id = test_relevant_contexts[test_sample_question_id][0]\n",
        "logger.info(f\"Relevant document ID: {test_sample_relevant_doc_id}\")\n",
        "test_sample_doc_content = test_corpus[test_sample_relevant_doc_id]\n",
        "logger.info(f\"Sample document content: {test_sample_doc_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_jYOnAI43zK"
      },
      "source": [
        "### Reformating and Saving Datasets\n",
        "\n",
        "Now, we can save our datasets for later use!\n",
        "\n",
        "> NOTE: If you ran into issues creating the data - you can use the data from the DataRespository. It's simply called: `train_dataset.jsonl`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iF6IFFq9VsNu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:47.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mserialize\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mDataset serialized to /notebooks/DataRepository/training_dataset.jsonl\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mTraining dataset saved to /notebooks/DataRepository/training_dataset.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# training_corpus = {train_item.metadata[\"id\"] : train_item.page_content for train_item in training_split_documents}\n",
        "\n",
        "# train_dataset = {\n",
        "#     \"questions\" : training_questions,\n",
        "#     \"relevant_contexts\" : training_relevant_contexts,\n",
        "#     \"corpus\" : training_corpus\n",
        "# }\n",
        "training_dataset_path: Path = repo_root_path.joinpath(\"training_dataset.jsonl\")\n",
        "# train_generator.save_dataset_to_json(str(training_dataset_path))\n",
        "# with open(f\"{str(training_dataset_path)}\", \"w\") as f:\n",
        "#     json.dump(\n",
        "#         train_dataset, f, indent=4, default=lambda x: x.__dict__, ensure_ascii=False\n",
        "#     )\n",
        "train_dataset.serialize(str(training_dataset_path))\n",
        "logger.info(f\"Training dataset saved to {training_dataset_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PqF9WaueV-V8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:47.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mserialize\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mDataset serialized to /notebooks/DataRepository/val_dataset.jsonl\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mValidation dataset saved to /notebooks/DataRepository/val_dataset.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# val_corpus = {val_item.metadata[\"id\"] : val_item.page_content for val_item in val_split_documents}\n",
        "\n",
        "# val_dataset = {\n",
        "#     \"questions\" : val_questions,\n",
        "#     \"relevant_contexts\" : val_relevant_contexts,\n",
        "#     \"corpus\" : val_corpus\n",
        "# }\n",
        "# with open(\"val_dataset.jsonl\", \"w\") as f:\n",
        "#   json.dump(val_dataset, f)\n",
        "\n",
        "val_dataset_path: Path = repo_root_path.joinpath(\"val_dataset.jsonl\")\n",
        "# with open(f\"{str(val_dataset_path)}\", \"w\") as f:\n",
        "#     json.dump(\n",
        "#         val_dataset, f, indent=4, default=lambda x: x.__dict__, ensure_ascii=False\n",
        "#     )\n",
        "# val_generator.save_dataset_to_json(str(val_dataset_path))\n",
        "val_dataset.serialize(str(val_dataset_path))\n",
        "logger.info(f\"Validation dataset saved to {val_dataset_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0DSQ7WMnWAu6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:47.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mserialize\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mDataset serialized to /notebooks/DataRepository/test_dataset.jsonl\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTest dataset saved to /notebooks/DataRepository/test_dataset.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# train_corpus = {test_item.metadata[\"id\"] : test_item.page_content for test_item in test_split_documents}\n",
        "\n",
        "# test_dataset = {\n",
        "#     \"questions\" : test_questions,\n",
        "#     \"relevant_contexts\" : test_relevant_contexts,\n",
        "#     \"corpus\" : train_corpus\n",
        "# }\n",
        "# with open(\"test_dataset.jsonl\", \"w\") as f:\n",
        "#   json.dump(test_dataset, f)\n",
        "test_dataset_path: Path = repo_root_path.joinpath(\"test_dataset.jsonl\")\n",
        "\n",
        "# with open(f\"{str(test_dataset_path)}\", \"w\") as f:\n",
        "#     json.dump(\n",
        "#         test_dataset, f, indent=4, default=lambda x: x.__dict__, ensure_ascii=False\n",
        "#     )\n",
        "# test_generator.save_dataset_to_json(str(test_dataset_path))\n",
        "test_dataset.serialize(str(test_dataset_path))\n",
        "logger.info(f\"Test dataset saved to {test_dataset_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAwklqQCgVi-"
      },
      "source": [
        "## Task 4: Fine-tuning `snowflake-arctic-embed-m`\n",
        "\n",
        "Now that we have a dataset, let's grab a `sentence-transformers` Embeddings model!\n",
        "\n",
        "We'll be using Snowflake's [`snowflake-arctic-embed-m`](https://huggingface.co/Snowflake/snowflake-arctic-embed-m) as a base embeddings model.\n",
        "\n",
        "It is a well performing embeddings model by itself, but there's a lot of very specific domain terms and vocabulary in our courpus - so lets fine-tune it and see what that can do for us!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- We'll grab some necessary imports from `sentence_transformers` and `torch`. -->\n",
        "\n",
        "> NOTE: PyTorch (`torch`) is a popular machine learning library - while we don't go very deep into PyTorch it's an incredibly powerful and interesting library! Please read more about it [here](https://pytorch.org/tutorials/beginner/basics/intro.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import re\n",
        "from typing import  List, Optional\n",
        "from loguru import logger\n",
        "from packaging import version\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.torch_version import TorchVersion\n",
        "\n",
        "class SentenceTransformerFactory:\n",
        "    \"\"\"\n",
        "    Factory class for creating and validating SentenceTransformer models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, model_name: str, validation_sentences: Optional[List[str]] = None\n",
        "    ) -> None:\n",
        "        self.model_name: str = model_name\n",
        "        self.validation_sentences: Optional[List[str]] = validation_sentences\n",
        "        self.version_constraints: Dict[str, str] = self._get_version_constraints()\n",
        "        logger.info(f\"Initialized SentenceTransformerFactory with model: {model_name}\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def create(self) -> SentenceTransformer:\n",
        "        \"\"\"\n",
        "        Create and validate the SentenceTransformer model.\n",
        "        \"\"\"\n",
        "        self._run_all_sanity_checks()\n",
        "        model = SentenceTransformer(self.model_name)\n",
        "        logger.info(f\"Loaded SentenceTransformer model: {self.model_name}\")\n",
        "        if self.validation_sentences:\n",
        "            self._validate_model(model)\n",
        "        return model\n",
        "    \n",
        "    @logger.catch(reraise=True)\n",
        "    def _get_version_constraints(self) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Fetch model metadata from Hugging Face and extract version constraints.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Fetching version constraints for model: {self.model_name}\")\n",
        "        base_url: str = f\"https://huggingface.co/{self.model_name}/raw/main/\"\n",
        "        files_to_check: List[str] = [\n",
        "            \"modules.json\",\n",
        "            \"config.json\",\n",
        "            \"config_sentence_transformers.json\",\n",
        "        ]\n",
        "        version_constraints = {}\n",
        "        for file_name in files_to_check:\n",
        "            url = base_url + file_name\n",
        "            try:\n",
        "                logger.debug(f\"Fetching metadata from: {url}\")\n",
        "                response = requests.get(url)\n",
        "                response.raise_for_status()\n",
        "                data = json.loads(response.text)\n",
        "                logger.debug(f\"Successfully fetched metadata from: {url}\")\n",
        "\n",
        "                # Merge version constraints if present\n",
        "                if \"__version__\" in data:\n",
        "                    version_info = data[\"__version__\"]\n",
        "                    version_constraints.update(version_info)\n",
        "                    logger.debug(f\"Extracted version constraints: {version_info}\")\n",
        "            except requests.HTTPError as e:\n",
        "                logger.warning(f\"Failed to fetch {file_name} from Hugging Face: {e}\")\n",
        "            except json.JSONDecodeError as e:\n",
        "                logger.warning(f\"Failed to parse JSON from {file_name}: {e}\")\n",
        "        if not version_constraints:\n",
        "            logger.warning(\"No version constraints found in model metadata.\")\n",
        "        return version_constraints\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _run_all_sanity_checks(self) -> None:\n",
        "        \"\"\"\n",
        "        Run sanity checks for required packages and versions.\n",
        "        \"\"\"\n",
        "        self._sanity_check_numpy()\n",
        "        self._sanity_check_cuda()\n",
        "        self._sanity_check_package(\"torch\")\n",
        "        self._sanity_check_package(\"transformers\")\n",
        "        self._sanity_check_package(\"sentence_transformers\")\n",
        "        logger.info(\"All sanity checks passed.\")\n",
        "\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _sanity_check_package(self, package_name: str) -> None:\n",
        "        \"\"\"\n",
        "        Check if the installed version of a package meets the required version.\n",
        "        \"\"\"\n",
        "        required_version = self.version_constraints.get(package_name)\n",
        "        if not required_version:\n",
        "            logger.info(f\"No version constraint specified for {package_name}. Skipping check.\")\n",
        "            return\n",
        "        try:\n",
        "            module = __import__(package_name)\n",
        "            installed_version = module.__version__\n",
        "            if not self._compare_versions(installed_version, required_version):\n",
        "                raise ImportError(\n",
        "                    f\"{package_name} version must be >= {required_version}, but found {installed_version}\"\n",
        "                )\n",
        "            logger.info(f\"{package_name} version {installed_version} meets the requirement.\")\n",
        "        except ImportError as e:\n",
        "            raise ImportError(f\"Failed to import {package_name}: {e}\")\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _compare_versions(installed_version: str, required_version: str) -> bool:\n",
        "        \"\"\"\n",
        "        Compare two version strings.\n",
        "        \"\"\"\n",
        "        installed_ver = version.parse(installed_version)\n",
        "        required_ver = version.parse(required_version)\n",
        "        return installed_ver >= required_ver\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _sanity_check_numpy() -> None:\n",
        "        import numpy as np\n",
        "        required_version = \"1.16.0\"\n",
        "        installed_version: str = np.__version__\n",
        "        if version.parse(installed_version) < version.parse(required_version):\n",
        "            raise ImportError(f\"NumPy version must be >= {required_version}, found {installed_version}\")\n",
        "        logger.info(f\"NumPy version {installed_version} is adequate.\")\n",
        "\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def _sanity_check_cuda() -> None:\n",
        "      import torch\n",
        "      if not torch.cuda.is_available():\n",
        "          raise RuntimeError(\"CUDA is not available. Please ensure CUDA is installed and properly configured.\")\n",
        "      logger.info(f\"CUDA version: {torch.version.cuda}\")\n",
        "      logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    \n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _validate_model(self, model: SentenceTransformer) -> None:\n",
        "        \"\"\"\n",
        "        Validate the model by encoding validation sentences.\n",
        "        \"\"\"\n",
        "        if self.validation_sentences is None:\n",
        "            logger.info(\"skipping model encoding validation\")\n",
        "            return\n",
        "        embeddings = model.encode(self.validation_sentences)\n",
        "        if embeddings is None or len(embeddings) != len(self.validation_sentences):\n",
        "            raise ValueError(\"Model validation failed: Embeddings not generated correctly.\")\n",
        "        logger.info(\"Model validation successful.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:47.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mFetching version constraints for model: Snowflake/snowflake-arctic-embed-m\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.817\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mFetching metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/modules.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mSuccessfully fetched metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/modules.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.870\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mFetching metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/config.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.937\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mSuccessfully fetched metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/config.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:47.938\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mFetching metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/config_sentence_transformers.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mSuccessfully fetched metadata from: https://huggingface.co/Snowflake/snowflake-arctic-embed-m/raw/main/config_sentence_transformers.json\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_get_version_constraints\u001b[0m:\u001b[36m61\u001b[0m - \u001b[34m\u001b[1mExtracted version constraints: {'sentence_transformers': '2.7.0.dev0', 'transformers': '4.39.3', 'pytorch': '2.1.0+cu121'}\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mInitialized SentenceTransformerFactory with model: Snowflake/snowflake-arctic-embed-m\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_numpy\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mNumPy version 1.26.4 is adequate.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_cuda\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mCUDA version: 11.8\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_cuda\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mGPU: Quadro P5000\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_package\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mNo version constraint specified for torch. Skipping check.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_package\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mtransformers version 4.40.0 meets the requirement.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_sanity_check_package\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1msentence_transformers version 2.7.0 meets the requirement.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:48.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_all_sanity_checks\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mAll sanity checks passed.\u001b[0m\n",
            "WARNING:sentence_transformers.SentenceTransformer:You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n",
            "/root/.cache/pypoetry/virtualenvs/fine-tuning-embedding-models-XvMgmHVc-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/root/.cache/pypoetry/virtualenvs/fine-tuning-embedding-models-XvMgmHVc-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\u001b[32m2024-09-19 01:25:51.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoaded SentenceTransformer model: Snowflake/snowflake-arctic-embed-m\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:52.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_validate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mModel validation successful.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model_id: str = \"Snowflake/snowflake-arctic-embed-m\"\n",
        "validation_sentences: List[str] = [\n",
        "    \"This is a custom validation sentence\",\n",
        "    \"Another custom sentence for validation\"\n",
        "]\n",
        "factory: SentenceTransformerFactory = SentenceTransformerFactory(model_id, validation_sentences)\n",
        "model: SentenceTransformer = factory.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJtPPlck8HBE"
      },
      "source": [
        "We're using a toy batch size here to reflect the limited number of examples we have.\n",
        "\n",
        "> NOTE: It is typical to use a much larger batch size (~64+), hardware permitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8Lokhy6KYHAv"
      },
      "outputs": [],
      "source": [
        "# BATCH_SIZE = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-6DT8hc8PmT"
      },
      "source": [
        "Let's move our dataset into the expected format for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JJk37zQsYJ4P"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers import InputExample\n",
        "\n",
        "# corpus = train_generator.get_corpus()\n",
        "# queries = train_dataset['questions']\n",
        "# relevant_docs = train_dataset['relevant_contexts']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# examples: List[InputExample] = []\n",
        "# for query_id, query in queries.items():\n",
        "#     doc_id = relevant_docs[query_id][0]\n",
        "#     text = corpus[doc_id]\n",
        "#     example = InputExample(texts=[query, text])\n",
        "#     examples.append(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjFx7KHI8TL0"
      },
      "source": [
        "Now we can create a `torch` `DataLoader`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tiizmeIqZ_-w"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "# # FIXME: the type is wrong\n",
        "# # Argument of type \"List[InputExample]\" cannot be assigned to parameter \"dataset\" of type \"Dataset[T_co@DataLoader]\" in function \"__init__\"\n",
        "# #   \"List[InputExample]\" is incompatible with \"Dataset[T_co@DataLoader]\"PylancereportArgumentType\n",
        "# # (variable) examples: List[InputExample]\n",
        "# loader = DataLoader(\n",
        "#     examples, batch_size=BATCH_SIZE\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vA8rzlX8XbT"
      },
      "source": [
        "Next up, we'll prepare our loss function!\n",
        "\n",
        "Loss is an important part of training, fine-tuning, and more. If you want a deep dive on loss - you can check out our [event on loss!](https://www.youtube.com/watch?v=iB8FWR9aD5Q&t=8s).\n",
        "\n",
        "The core loss we're using today is called `MultipleNegativesRankingLoss` - you can find more information [here](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py).\n",
        "\n",
        "This is \"wrapped\" in `MatryoshkaLoss`, which you can read the implementation of [here](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MatryoshkaLoss.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Uga4nnBqlVeh"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "\n",
        "# matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
        "# inner_train_loss = MultipleNegativesRankingLoss(model)\n",
        "# train_loss = MatryoshkaLoss(\n",
        "#     model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJG4fOm66PHI"
      },
      "source": [
        "##### ðŸ—ï¸ Activity #2:\n",
        "\n",
        "Both of these losses sound \"cool\", but what are they - exactly - under the hood?\n",
        "\n",
        "Why are these losses specifically doing? Please write a short summary of each loss.\n",
        "\n",
        "> NOTE: This is a course focused on AI Engineering and the application of AI - looking for a hint? Try pasting the code (linked above) into ChatGPT/Claude to write the summary!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "###### `MultipleNegativesRankingLoss`:\n",
        "\n",
        "This loss function is crucial for training sentence embeddings, especially for retrieval tasks. It uses contrastive learning to teach the model how to distinguish between similar and dissimilar pairs of sentences.\n",
        "\n",
        "How it works (with a detailed example):\n",
        "\n",
        "Let's say we have a batch of 3 sentence pairs:\n",
        "- (Q1, D1): \"What is AI?\" and \"Artificial Intelligence is a field of computer science...\"\n",
        "- (Q2, D2): \"How does photosynthesis work?\" and \"Photosynthesis is a process used by plants...\"\n",
        "- (Q3, D3): \"Who wrote Romeo and Juliet?\" and \"Romeo and Juliet was written by William Shakespeare...\"\n",
        "\n",
        "Step 1: Embedding the sentences\n",
        "First, the model converts each sentence into a numerical vector (embedding). Let's simplify and say we're using 3-dimensional embeddings for this example:\n",
        "\n",
        "- Q1: [0.5, 0.3, 0.8]\n",
        "- D1: [0.6, 0.2, 0.7]\n",
        "- Q2: [-0.2, 0.9, 0.1]\n",
        "- D2: [-0.3, 0.8, 0.2]\n",
        "- Q3: [0.1, -0.5, 0.7]\n",
        "- D3: [0.2, -0.4, 0.6]\n",
        "\n",
        "Step 2: Computing similarities\n",
        "The model computes the similarity between Q1 and all other sentences using dot product:\n",
        "\n",
        "- sim(Q1, D1) = 0.5*0.6 + 0.3*0.2 + 0.8*0.7 = 0.91 (positive pair)\n",
        "- sim(Q1, Q2) = 0.5*(-0.2) + 0.3*0.9 + 0.8*0.1 = 0.35 (negative)\n",
        "- sim(Q1, D2) = 0.5*(-0.3) + 0.3*0.8 + 0.8*0.2 = 0.37 (negative)\n",
        "- sim(Q1, Q3) = 0.5*0.1 + 0.3*(-0.5) + 0.8*0.7 = 0.51 (negative)\n",
        "- sim(Q1, D3) = 0.5*0.2 + 0.3*(-0.4) + 0.8*0.6 = 0.58 (negative)\n",
        "\n",
        "Step 3: Applying softmax\n",
        "These similarities are then passed through a softmax function to convert them into probabilities:\n",
        "\n",
        "```python\n",
        "softmax([0.91, 0.35, 0.37, 0.51, 0.58]) â‰ˆ [0.40, 0.12, 0.12, 0.17, 0.19]\n",
        "```\n",
        "Step 4: Computing the loss\n",
        "The loss is computed as the negative log of the probability assigned to the positive pair:\n",
        "\n",
        "```python\n",
        "loss = -log(0.40) â‰ˆ 0.92\n",
        "```\n",
        "\n",
        "This process is repeated for each query in the batch (Q2 and Q3), and the losses are averaged.\n",
        "\n",
        "How this encourages the desired behavior:\n",
        "1. To minimize this loss, the model needs to increase the similarity of Q1 and D1 relative to the other pairs.\n",
        "2. If it does this successfully, the probability assigned to (Q1, D1) will increase, and the loss will decrease.\n",
        "3. Simultaneously, this process pushes the embeddings of dissimilar sentences further apart in the vector space.\n",
        "\n",
        "Over many training iterations, this leads to a model that produces embeddings where similar sentences are closer together and dissimilar sentences are further apart.\n",
        "\n",
        "###### 2. `MatryoshkaLoss`:\n",
        "\n",
        "MatryoshkaLoss extends this concept to multiple embedding sizes simultaneously. Here's a more detailed explanation:\n",
        "\n",
        "How it works (with an example):\n",
        "\n",
        "Let's say we're using dimensions [`768`, `512`, `256`, `128`, `64`] and we have a sentence: \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "Step 1: Generating embeddings\n",
        "The model produces a 768-dimensional embedding for this sentence. Let's simplify\n",
        "and say the first 10 dimensions look like this:\n",
        "\n",
        "```python\n",
        "[0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...]\n",
        "```\n",
        "\n",
        "Step 2: Creating slices\n",
        "MatryoshkaLoss creates slices of this embedding:\n",
        "- 768-dim: [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...] (all 768 dimensions)\n",
        "- 512-dim: [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...] (first 512 dimensions)\n",
        "- 256-dim: [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...] (first 256 dimensions)\n",
        "- 128-dim: [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...] (first 128 dimensions)\n",
        "- 64-dim: [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.6, -0.2, 0.3, 0.7, ...] (first 64 dimensions)\n",
        "\n",
        "Step 3: Applying `MultipleNegativesRankingLoss`\n",
        "For each slice, the `MultipleNegativesRankingLoss` is computed as described earlier.\n",
        "\n",
        "Step 4: Combining losses\n",
        "\n",
        "The losses from each slice are combined, often with equal weights:\n",
        "\n",
        "```python\n",
        "total_loss = (loss_768 + loss_512 + loss_256 + loss_128 + loss_64) / 5\n",
        "```\n",
        "\n",
        "Significance of `matryoshka_dimensions` [`768`, `512`, `256`, `128`, `64`]:\n",
        "\n",
        "1. 768: This is often the base dimension for models like BERT. It provides the highest information capacity.\n",
        "2. 512, 256, 128, 64: Each subsequent dimension is roughly half of the previous one. This logarithmic scale provides a good spread of sizes.\n",
        "3. Range: From 768 to 64, it covers use cases from high-resource environments to very constrained ones.\n",
        "4. Powers of 2: These dimensions are computationally efficient in many systems.\n",
        "\n",
        "You could choose different numbers based on your specific needs. For example:\n",
        "- [1024, 512, 256, 128] for larger base embeddings\n",
        "- [512, 384, 256, 192, 128] for more granularity in the middle range\n",
        "\n",
        "The combination of MultipleNegativesRankingLoss and MatryoshkaLoss allows the fine-tuning process to:\n",
        "1. Improve embedding quality for retrieval tasks across multiple dimensions.\n",
        "2. Create a single, flexible model adaptable to various computational environments.\n",
        "3. Potentially enhance generalization by maintaining information across different embedding sizes.\n",
        "\n",
        "This approach is particularly valuable when you need a versatile model that can be deployed in various settings or used for different downstream tasks with varying computational constraints.\n",
        "\n",
        "By training with these losses, you're essentially creating a \"Swiss Army knife\" of an embedding model â€“ one tool that can adapt to many different situations and requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKxRuXfH844c"
      },
      "source": [
        "Now we can set-up our evaluator.\n",
        "\n",
        "> NOTE: Due to the formatting of our dataset - this is all we have to do!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "f0hAFwUyaHQG"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "\n",
        "# corpus = val_dataset['corpus']\n",
        "# queries = val_dataset['questions']\n",
        "# relevant_docs = val_dataset['relevant_contexts']\n",
        "\n",
        "# evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYfap_ct8-bU"
      },
      "source": [
        "We'll train this model for 5 epochs, though you could increase this number if we had a significant amount more data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "svZG0pBHiQr6"
      },
      "outputs": [],
      "source": [
        "# EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxitWoNX9DwW"
      },
      "source": [
        "It's training time!\n",
        "\n",
        "> NOTE: We're manually defining a warm-up period here - this is just to provide a smooth ramp into our training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import transformers\n",
        "# import accelerate\n",
        "\n",
        "# print(transformers.__version__)\n",
        "# print(accelerate.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "e7fc4c0a3c344e98808ff1d73115eefb",
            "e51a3ed6a276432cb81a3b3485dc6147",
            "0ecafb90cca943f6a1ba1b29c1b8d997",
            "c536f9207bde42f3b51cb38e3659653e",
            "c8713888466944378baf79f547a3c704",
            "ed5a932408e547f99ea5a882fc1630fa",
            "5d7bdcc9e64f44d29385b053bda75132",
            "ab848092a25549e79d67666692477e76",
            "f55a8ca4877243929e4295dfd770c54b",
            "a125b06e1a6b44cdbb08a9319e7b8ab4",
            "25e7849a677947ed87bc2013ad272193"
          ]
        },
        "id": "aDhUHZY-iR09",
        "outputId": "19cf386c-43a1-4b73-f926-d78805551bb9"
      },
      "outputs": [],
      "source": [
        "# warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
        "\n",
        "# model.fit(\n",
        "#     train_objectives=[(loader, train_loss)],\n",
        "#     epochs=EPOCHS,\n",
        "#     warmup_steps=warmup_steps,\n",
        "#     output_path='finetuned_arctic',\n",
        "#     show_progress_bar=True,\n",
        "#     evaluator=evaluator,\n",
        "#     evaluation_steps=50,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from typing import Dict, List, Optional, Union,Iterator\n",
        "# from sentence_transformers import SentenceTransformer, InputExample\n",
        "# from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "# from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "# # TODO: having two datasets is dumb\n",
        "# from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
        "# from datasets import Dataset as HuggingFaceDataset\n",
        "# from loguru import logger\n",
        "\n",
        "# class InputExampleDataset(TorchDataset):\n",
        "#     def __init__(self, examples):\n",
        "#         self.examples = [InputExample(texts=[ex['query'], ex['context']]) if isinstance(ex, dict) else ex for ex in examples]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.examples)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.examples[idx]\n",
        "\n",
        "#     def __iter__(self):\n",
        "#         return iter(self.examples)\n",
        "# class EmbeddingFinetuner:\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         model: SentenceTransformer,\n",
        "#         train_dataset: HuggingFaceDataset,\n",
        "#         val_dataset: HuggingFaceDataset,\n",
        "#         matryoshka_dims: List[int] = [768, 512, 256, 128, 64],\n",
        "#         batch_size: int = 20,\n",
        "#         epochs: int = 5\n",
        "#     ):\n",
        "#         self.model = model\n",
        "#         self.matryoshka_dims = matryoshka_dims\n",
        "#         self.batch_size = batch_size\n",
        "#         self.epochs = epochs\n",
        "#         self.train_dataloader: Optional[DataLoader] = None\n",
        "#         self.train_loss: Optional[MatryoshkaLoss] = None\n",
        "#         self.evaluator: Optional[InformationRetrievalEvaluator] = None\n",
        "\n",
        "#         self.train_dataset = train_dataset\n",
        "#         self.val_dataset = val_dataset\n",
        "\n",
        "#         logger.info(f\"EmbeddingFinetuner initialized with model: {model.__class__.__name__}\")\n",
        "#     def _process_dataset(self, dataset: HuggingFaceDataset) -> InputExampleDataset:\n",
        "#         logger.info(f\"Processing dataset with {len(dataset)} examples\")\n",
        "#         processed_examples = []\n",
        "#         for example in dataset:\n",
        "#             processed_example = self._create_input_example(example)\n",
        "#             if processed_example is not None:\n",
        "#                 processed_examples.append(processed_example)\n",
        "        \n",
        "#         logger.info(f\"Processed dataset now has {len(processed_examples)} examples\")\n",
        "#         return InputExampleDataset(processed_examples)\n",
        "#     @staticmethod\n",
        "#     def _create_input_example(example: Union[Dict[str, Union[str, List[str]]], str]) -> Optional[InputExample]:\n",
        "#         if isinstance(example, dict):\n",
        "#             if 'doc_id' in example:\n",
        "#                 # Case when doc_id exists (unprocessed input)\n",
        "#                 query = example.get('questions')\n",
        "#                 relevant_contexts = example.get('relevant_contexts')\n",
        "#                 corpus = example.get('corpus')\n",
        "\n",
        "#                 if not isinstance(query, str) or not isinstance(relevant_contexts, list) or not isinstance(corpus, dict):\n",
        "#                     logger.error(f\"Unexpected types: query {type(query)}, relevant_contexts {type(relevant_contexts)}, corpus {type(corpus)}. Expected str, list, dict respectively.\")\n",
        "#                     return None\n",
        "\n",
        "#                 if not relevant_contexts:\n",
        "#                     logger.error(\"relevant_contexts is empty.\")\n",
        "#                     return None\n",
        "\n",
        "#                 doc_id = relevant_contexts[0]\n",
        "#                 text = corpus.get(doc_id, \"\")\n",
        "#                 return InputExample(texts=[query, text])\n",
        "#             else:\n",
        "#                 # Case for already processed input\n",
        "#                 query = example.get('query')\n",
        "#                 context = example.get('context')\n",
        "                \n",
        "#                 if not isinstance(query, str) or not isinstance(context, str):\n",
        "#                     logger.error(f\"Unexpected types: query {type(query)}, context {type(context)}. Expected str for both.\")\n",
        "#                     return None\n",
        "                \n",
        "#                 return InputExample(texts=[query, context])\n",
        "#         elif isinstance(example, str):\n",
        "#             # If the example is a string, assume it's the query and there's no context\n",
        "#             logger.warning(\"Received a string example. Treating it as a query with no context.\")\n",
        "#             return InputExample(texts=[example, \"\"])\n",
        "#         else:\n",
        "#             logger.error(f\"Unexpected example type: {type(example)}. Expected dict or str.\")\n",
        "#             return None\n",
        "#     def _prepare_training_data(self) -> None:\n",
        "#         logger.info(\"Preparing training data\")\n",
        "        \n",
        "#         corpus = self.train_dataset['corpus']\n",
        "#         queries = self.train_dataset['questions']\n",
        "#         relevant_docs = self.train_dataset['relevant_contexts']\n",
        "        \n",
        "#         processed_examples = []\n",
        "#         for query_id, query in queries.items():\n",
        "#             doc_id = relevant_docs[query_id][0]  # Assuming we're using the first relevant doc\n",
        "#             text = corpus[doc_id]\n",
        "#             processed_examples.append(InputExample(texts=[query, text]))\n",
        "        \n",
        "#         dataset = InputExampleDataset(processed_examples)\n",
        "#         self.train_dataloader = DataLoader(\n",
        "#             dataset, batch_size=self.batch_size, shuffle=True\n",
        "#         )\n",
        "        \n",
        "#         logger.debug(f\"Training data prepared. Total examples: {len(processed_examples)}\")\n",
        "#     def _prepare_evaluator(self) -> None:\n",
        "#         logger.info(\"Preparing evaluator\")\n",
        "        \n",
        "#         processed_dataset = self._process_dataset(self.val_dataset)\n",
        "#         queries = {}\n",
        "#         corpus = {}\n",
        "        \n",
        "#         for i, example in enumerate(processed_dataset):\n",
        "#             if isinstance(example, InputExample):\n",
        "#                 queries[str(i)] = example.texts[0]\n",
        "#                 corpus[str(i)] = example.texts[1]\n",
        "#             elif isinstance(example, dict):\n",
        "#                 queries[str(i)] = example['query']\n",
        "#                 corpus[str(i)] = example['context']\n",
        "#             else:\n",
        "#                 logger.warning(f\"Unexpected type in processed_dataset: {type(example)}. Skipping.\")\n",
        "        \n",
        "#         relevant_docs = {str(i): {str(i)} for i in range(len(queries))}\n",
        "        \n",
        "#         self.evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)\n",
        "#         logger.debug(f\"Created InformationRetrievalEvaluator with {len(queries)} queries and {len(corpus)} documents\")\n",
        "#     def _prepare_loss_function(self) -> None:\n",
        "#         logger.info(\"Preparing loss function\")\n",
        "#         inner_train_loss = MultipleNegativesRankingLoss(self.model)\n",
        "#         self.train_loss = MatryoshkaLoss(self.model, inner_train_loss, matryoshka_dims=self.matryoshka_dims)\n",
        "#         logger.debug(f\"Created MatryoshkaLoss with dimensions: {self.matryoshka_dims}\")\n",
        "\n",
        "#     def train(self, output_path: str) -> None:\n",
        "#         logger.info(f\"Starting training process. Output path: {output_path}\")\n",
        "#         self._prepare_training_data()\n",
        "#         self._prepare_loss_function()\n",
        "#         self._prepare_evaluator()\n",
        "\n",
        "#         if not self.train_dataloader or not self.train_loss or not self.evaluator:\n",
        "#             logger.error(\"Training components not properly initialized\")\n",
        "#             raise ValueError(\"Training components not properly initialized\")\n",
        "\n",
        "#         warmup_steps = int(len(self.train_dataloader) * self.epochs * 0.1)\n",
        "#         logger.debug(f\"Warmup steps: {warmup_steps}\")\n",
        "\n",
        "#         self.model.fit(\n",
        "#             train_objectives=[(self.train_dataloader, self.train_loss)],\n",
        "#             epochs=self.epochs,\n",
        "#             warmup_steps=warmup_steps,\n",
        "#             output_path=output_path,\n",
        "#             show_progress_bar=True,\n",
        "#             evaluator=self.evaluator,\n",
        "#             evaluation_steps=50,\n",
        "#         )\n",
        "#         logger.info(\"Training completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import  List, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from torch.utils.data import DataLoader\n",
        "from loguru import logger\n",
        "\n",
        "class EmbeddingFinetuner:\n",
        "    \"\"\"\n",
        "    Fine-tunes an embedding model with the provided training data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: SentenceTransformer,\n",
        "        train_dataset: QADataset,\n",
        "        val_dataset: QADataset,\n",
        "        matryoshka_dims: List[int] = [768, 512, 256, 128, 64],\n",
        "        batch_size: int = 20,\n",
        "        epochs: int = 5,\n",
        "    ):\n",
        "        self.model: SentenceTransformer = model\n",
        "        self.matryoshka_dims: List[int] = matryoshka_dims\n",
        "        self.batch_size: int = batch_size\n",
        "        self.epochs: int = epochs\n",
        "        self.train_dataloader: Optional[DataLoader] = None\n",
        "        self.train_loss: Optional[MatryoshkaLoss] = None\n",
        "        self.evaluator: Optional[InformationRetrievalEvaluator] = None\n",
        "        self.train_dataset: QADataset = train_dataset\n",
        "        self.val_dataset: QADataset = val_dataset\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _prepare_training_data(self) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the training data loader.\n",
        "        \"\"\"\n",
        "        if not isinstance(self.train_dataset, Dataset):\n",
        "          raise TypeError(\"train_dataset must be an instance of torch.utils.data.Dataset\")\n",
        "        self.train_dataloader = DataLoader(\n",
        "            self.train_dataset, shuffle=True, batch_size=self.batch_size\n",
        "        )\n",
        "        logger.info(f\"Prepared training data with {len(self.train_dataset)} examples.\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _prepare_evaluator(self) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the evaluator using the validation dataset.\n",
        "        \"\"\"\n",
        "        queries = self.val_dataset.get_questions()\n",
        "        corpus = self.val_dataset.get_corpus()\n",
        "        relevant_contexts = self.val_dataset.get_relevant_contexts()\n",
        "        relevant_docs = {qid: set(doc_ids) for qid, doc_ids in relevant_contexts.items()}\n",
        "        self.evaluator = InformationRetrievalEvaluator(\n",
        "            queries=queries,\n",
        "            corpus=corpus,\n",
        "            relevant_docs=relevant_docs,\n",
        "            show_progress_bar=True,\n",
        "        )\n",
        "        logger.info(\"Evaluator prepared.\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def _prepare_loss_function(self) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the loss function for training.\n",
        "        \"\"\"\n",
        "        inner_train_loss = MultipleNegativesRankingLoss(self.model)\n",
        "        self.train_loss = MatryoshkaLoss(\n",
        "            self.model, inner_train_loss, matryoshka_dims=self.matryoshka_dims\n",
        "        )\n",
        "        logger.info(\"Loss function prepared.\")\n",
        "  \n",
        "    @logger.catch(reraise=True)\n",
        "    def train(self, output_path: str) -> None:\n",
        "        \"\"\"\n",
        "        Train the embedding model.\n",
        "        \"\"\"\n",
        "        self._prepare_training_data()\n",
        "        self._prepare_loss_function()\n",
        "        self._prepare_evaluator()\n",
        "        if not self.train_dataloader or not self.train_loss or not self.evaluator:\n",
        "            raise ValueError(\"Training components not properly initialized\")\n",
        "        warmup_steps = int(len(self.train_dataloader) * self.epochs * 0.1)\n",
        "        self.model.fit(\n",
        "            train_objectives=[(self.train_dataloader, self.train_loss)],\n",
        "            epochs=self.epochs,\n",
        "            warmup_steps=warmup_steps,\n",
        "            evaluator=self.evaluator,\n",
        "            evaluation_steps=50,\n",
        "            output_path=output_path,\n",
        "            show_progress_bar=True,\n",
        "        )\n",
        "        logger.info(\"Model training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetuned_model_output_path:str=\"finetuned_arctic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:25:54.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_prepare_training_data\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mPrepared training data with 1440 examples.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:54.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_prepare_loss_function\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mLoss function prepared.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:25:54.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_prepare_evaluator\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mEvaluator prepared.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6baa90b30274090b5bd24e94633c229",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b94b1c06655b4ba4b522898abc678332",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b0aac0c09444df788924e023db686e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.44s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd2e9886a754485292bd58145521af95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.46s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c56956466dad457394bd0aeeb0242eda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4e808ae52894e7ea4b55667e44e0895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4671dedc679428d9147da7043f97aeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.39s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4469099cedd046cea000a72bfb010888",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4720dbefaa14d55ae64ba2deb6d1eb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1f63abf7ad74bcd820447aa83891dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976f828cf4ab4c779c9c1c5ff347949d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "854495162f204df295cb971bb7f057e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.41s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1c2b9e5700a4604bac0cbaf71bbb246",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2506cf38a42248a08c93cd5d1c3e32c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed78979c3ec4fbd84bd8484bd509ea8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.42s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7751d262d6a4478bec35b82754a57da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corpus Chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n",
            "\u001b[32m2024-09-19 01:29:49.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mModel training complete.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "finetuner = EmbeddingFinetuner(\n",
        "  model=model,\n",
        "  train_dataset=train_dataset,\n",
        "  val_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "finetuner.train(output_path=finetuned_model_output_path)\n",
        "model: SentenceTransformer = finetuner.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bo0zW5k9Poq"
      },
      "source": [
        "## Task 5: Evaluating our Retriever\n",
        "\n",
        "Now that we have fine-tuned our retriever - let's see if it's worthwhile!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Vq-2oqU0wHFr"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# from langchain_community.vectorstores import FAISS\n",
        "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "# from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jD0qrIh9X8f"
      },
      "source": [
        "<!-- Now we'll define a function that will help us evaluate our retrieval process.\n",
        "\n",
        "> NOTE: We're assuming 1 correct document in a \"hit\". -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0713_3cowX4q"
      },
      "outputs": [],
      "source": [
        "# from tqdm.notebook import tqdm_notebook\n",
        "# def evaluate_openai(\n",
        "#     dataset,\n",
        "#     embed_model,\n",
        "#     top_k=5,\n",
        "#     verbose=False,\n",
        "# ):\n",
        "#   corpus = dataset['corpus']\n",
        "#   questions = dataset['questions']\n",
        "#   relevant_docs = dataset['relevant_contexts']\n",
        "#   documents = [Document(page_content=content, metadata={\"id\": doc_id}) for doc_id, content in corpus.items()]\n",
        "#   vectorstore = FAISS.from_documents(documents, embed_model)\n",
        "\n",
        "#   retriever = vectorstore.as_retriever(search_kwargs={\"k\": top_k})\n",
        "\n",
        "#   eval_results = []\n",
        "#   for id, question in  tqdm_notebook(questions.items(), desc=\"Evaluating  retrieval\"):\n",
        "#     retrieved_nodes = retriever.invoke(question)\n",
        "#     retrieved_ids = [node.metadata[\"id\"] for node in retrieved_nodes]\n",
        "#     expected_id = relevant_docs[id][0]\n",
        "#     is_hit = expected_id in retrieved_ids\n",
        "#     eval_results.append({\"id\": id, \"question\": question, \"expected_id\": expected_id, \"is_hit\": is_hit})\n",
        "\n",
        "#   return eval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start with an Evaluator class to help with checking results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Union, Set, Dict, Optional\n",
        "\n",
        "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from loguru import logger\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "@dataclass\n",
        "class EvaluationResult:\n",
        "    question_id: str\n",
        "    question: str\n",
        "    retrieved_ids: List[str]\n",
        "    expected_ids: Set[str]\n",
        "    is_hit: bool\n",
        "    rank: Optional[int] = None  # Rank of the first relevant document\n",
        "@dataclass\n",
        "class EvaluationMetrics:\n",
        "    model_name: str\n",
        "    hit_rate: float\n",
        "    mrr: float\n",
        "    total_questions: int\n",
        "\n",
        "class Evaluator:\n",
        "    \"\"\"\n",
        "    Provides methods to evaluate embedding models on a given QADataset.\n",
        "    Stores evaluation results in the class state.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset: QADataset,\n",
        "        embed_model: Union[OpenAIEmbeddings, HuggingFaceEmbeddings],\n",
        "        top_k: int = 5,\n",
        "    ):\n",
        "        self.dataset = dataset\n",
        "        self.embed_model: Union[OpenAIEmbeddings, HuggingFaceEmbeddings] = embed_model\n",
        "        self.top_k = top_k\n",
        "        self.retriever: Optional[VectorStoreRetriever] = None\n",
        "        self.evaluation_results: List[EvaluationResult] = []\n",
        "        self.hit_rate: Optional[float] = None\n",
        "        self.mrr: Optional[float] = None\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def evaluate(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluate the embedding model on the dataset.\n",
        "        Stores results in the class state.\n",
        "        \"\"\"\n",
        "        self.prepare_retriever()\n",
        "        self.evaluate_all_questions()\n",
        "        self.compute_hit_rate()\n",
        "        self.compute_mean_reciprocal_rank()\n",
        "        logger.info(f\"Model evaluation complete. Hit Rate: {self.hit_rate}, MRR: {self.mrr}\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def prepare_retriever(self) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the retriever from the dataset corpus and embedding model.\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing vector store and retriever.\")\n",
        "        corpus = self.dataset.get_corpus()\n",
        "        documents = [\n",
        "            Document(page_content=content, metadata={\"id\": doc_id})\n",
        "            for doc_id, content in corpus.items()\n",
        "        ]\n",
        "        vectorstore = FAISS.from_documents(documents, self.embed_model)\n",
        "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": self.top_k})\n",
        "        logger.info(\"Retriever prepared.\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def evaluate_all_questions(self) -> None:\n",
        "        \"\"\"\n",
        "        Evaluate all questions in the dataset using the retriever.\n",
        "        Stores results in the class state.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting evaluation of all questions.\")\n",
        "        questions = self.dataset.get_questions()\n",
        "        relevant_contexts = self.dataset.get_relevant_contexts()\n",
        "        self.evaluation_results = []\n",
        "\n",
        "        for question_id, question in tqdm_notebook(questions.items(), desc=\"Evaluating model\"):\n",
        "            result = self.evaluate_question(\n",
        "                question_id, question, relevant_contexts\n",
        "            )\n",
        "            self.evaluation_results.append(result)\n",
        "        logger.info(\"Evaluation of all questions completed.\")\n",
        "\n",
        "    @logger.catch(reraise=True)\n",
        "    def evaluate_question(\n",
        "        self,\n",
        "        question_id: str,\n",
        "        question: str,\n",
        "        relevant_contexts: Dict[str, List[str]],\n",
        "    ) -> EvaluationResult:\n",
        "        \"\"\"\n",
        "        Evaluate a single question.\n",
        "        Returns an EvaluationResult object.\n",
        "        \"\"\"\n",
        "        logger.trace(f\"Evaluating question ID: {question_id}\")\n",
        "        if self.retriever is None:\n",
        "            raise ValueError(f\"Retriever is not initialized for question ID: {question_id}\")\n",
        "        retrieved_docs: List[Document] = self.retriever.invoke(question)\n",
        "        retrieved_ids = [doc.metadata[\"id\"] for doc in retrieved_docs]\n",
        "        expected_ids = set(relevant_contexts[question_id])\n",
        "        is_hit = bool(expected_ids.intersection(retrieved_ids))\n",
        "        # Find rank of first relevant document\n",
        "        rank = None\n",
        "        for idx, doc_id in enumerate(retrieved_ids, start=1):\n",
        "            if doc_id in expected_ids:\n",
        "                rank = idx\n",
        "                break\n",
        "        result = EvaluationResult(\n",
        "            question_id=question_id,\n",
        "            question=question,\n",
        "            retrieved_ids=retrieved_ids,\n",
        "            expected_ids=expected_ids,\n",
        "            is_hit=is_hit,\n",
        "            rank=rank,\n",
        "        )\n",
        "        logger.trace(f\"Evaluation Result for question ID {question_id}: {result}\")\n",
        "        return result\n",
        "\n",
        "    def compute_hit_rate(self) -> None:\n",
        "        \"\"\"\n",
        "        Compute hit rate from the evaluation results.\n",
        "        Stores the result in the class state.\n",
        "        \"\"\"\n",
        "        hits = sum(1 for result in self.evaluation_results if result.is_hit)\n",
        "        total = len(self.evaluation_results)\n",
        "        self.hit_rate = hits / total if total > 0 else 0.0\n",
        "        logger.info(f\"Computed hit rate: {self.hit_rate}\")\n",
        "\n",
        "    def compute_mean_reciprocal_rank(self) -> None:\n",
        "        \"\"\"\n",
        "        Compute Mean Reciprocal Rank (MRR) from the evaluation results.\n",
        "        Stores the result in the class state.\n",
        "        \"\"\"\n",
        "        reciprocal_ranks = []\n",
        "        for result in self.evaluation_results:\n",
        "            if result.rank:\n",
        "                reciprocal_ranks.append(1 / result.rank)\n",
        "            else:\n",
        "                reciprocal_ranks.append(0.0)\n",
        "        total = len(reciprocal_ranks)\n",
        "        self.mrr = sum(reciprocal_ranks) / total if total > 0 else 0.0\n",
        "        logger.info(f\"Computed Mean Reciprocal Rank (MRR): {self.mrr}\")\n",
        "\n",
        "    def generate_evaluation_report(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Generate a detailed evaluation report as a Pandas DataFrame.\n",
        "        \"\"\"\n",
        "        logger.info(\"Generating evaluation report.\")\n",
        "        data = []\n",
        "        for result in self.evaluation_results:\n",
        "            data.append({\n",
        "                'question_id': result.question_id,\n",
        "                'question': result.question,\n",
        "                'is_hit': result.is_hit,\n",
        "                'rank': result.rank,\n",
        "                'retrieved_ids': result.retrieved_ids,\n",
        "                'expected_ids': list(result.expected_ids),\n",
        "            })\n",
        "        df = pd.DataFrame(data)\n",
        "        logger.info(\"Evaluation report generated.\")\n",
        "        return df\n",
        "    @staticmethod\n",
        "    @logger.catch(reraise=True)\n",
        "    def compare_evaluations(\n",
        "        evaluation_data: List[Tuple[str, List[EvaluationResult]]]\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Compare multiple models based on their EvaluationResult lists.\n",
        "        Returns a Pandas DataFrame containing comparison metrics.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting comparison of evaluation results.\")\n",
        "        metrics_list: List[EvaluationMetrics] = []\n",
        "\n",
        "        for model_name, results in evaluation_data:\n",
        "            # Check if results is of type List[EvaluationResult]\n",
        "            # if not isinstance(results, list) or not all(isinstance(result, EvaluationResult) for result in results):\n",
        "            if not isinstance(results, list) :\n",
        "                print(type(results[0]).__name__)\n",
        "                raise ValueError(f\"Invalid results type for model {model_name}. Expected List[EvaluationResult]. Actual {type(results).__name__}\")\n",
        "            \n",
        "            hits = sum(1 for result in results if result.is_hit)\n",
        "            total = len(results)\n",
        "            hit_rate = hits / total if total > 0 else 0.0\n",
        "\n",
        "            reciprocal_ranks = []\n",
        "            for result in results:\n",
        "                if result.rank:\n",
        "                    reciprocal_ranks.append(1 / result.rank)\n",
        "                else:\n",
        "                    reciprocal_ranks.append(0.0)\n",
        "            mrr = sum(reciprocal_ranks) / total if total > 0 else 0.0\n",
        "\n",
        "            metrics = EvaluationMetrics(\n",
        "                model_name=model_name,\n",
        "                hit_rate=hit_rate,\n",
        "                mrr=mrr,\n",
        "                total_questions=total,\n",
        "            )\n",
        "            metrics_list.append(metrics)\n",
        "            logger.info(\n",
        "                f\"Computed metrics for {model_name} - Hit Rate: {hit_rate}, MRR: {mrr}\"\n",
        "            )\n",
        "\n",
        "        # Convert metrics into a DataFrame\n",
        "        comparison_df = pd.DataFrame([vars(metric) for metric in metrics_list])\n",
        "        logger.info(\"Comparison DataFrame created.\")\n",
        "        return comparison_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOr49m4O9lxY"
      },
      "source": [
        "All that's left to do is evaluate, we'll evaluate our model against:\n",
        "\n",
        "1. OpenAI's closed source `text-embedding-3-small`\n",
        "2. The base non-fine-tuned version of `Snowflake/snowflake-arctic-embed-m`.\n",
        "\n",
        "Let's see how it stacks up!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijaeYpf593IW"
      },
      "source": [
        "### `text-embedding-3-small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyY3PztaxnU3",
        "outputId": "2642685b-d86b-46d7-a8ed-00426f78b2e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:29:50.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mPreparing vector store and retriever.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:29:52.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mRetriever prepared.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:29:52.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mStarting evaluation of all questions.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "375643f5bc114af286603f15c5aa82a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating model:   0%|          | 0/310 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:08.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mEvaluation of all questions completed.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:08.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_hit_rate\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mComputed hit rate: 0.9870967741935484\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:08.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_mean_reciprocal_rank\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mComputed Mean Reciprocal Rank (MRR): 0.9381182795698925\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:08.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mModel evaluation complete. Hit Rate: 0.9870967741935484, MRR: 0.9381182795698925\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# te3_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "# te3_results = evaluate_openai(test_dataset, te3_openai)\n",
        "from typing import List\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "te3_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "te3_openai_evaluator = Evaluator(test_dataset, te3_openai, top_k=5)\n",
        "te3_openai_evaluator.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:09.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mOpenAI model hit rate: 0.9870967741935484\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:09.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mOpenAI model MRR: 0.9381182795698925\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:09.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mGenerating evaluation report.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:09.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mEvaluation report generated.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            question_id  \\\n",
            "0  ee57e704-11a2-494e-a23e-529d91141a5b   \n",
            "1  7b478e5a-3991-46f7-9935-726a76ee7b3f   \n",
            "2  9867205c-a82f-49f4-8fd5-713ab8d8bf14   \n",
            "3  682c1384-2df1-4788-896a-45629b573a34   \n",
            "4  9c287439-c95d-4d88-b82c-27ed2833a61d   \n",
            "\n",
            "                                            question  is_hit  rank  \\\n",
            "0  How does the size of the provider impact the c...    True   1.0   \n",
            "1  What are the simplified ways of compliance for...    True   1.0   \n",
            "2  How can AI systems be designed to ensure equit...    True   1.0   \n",
            "3  What ethical considerations should be taken in...    True   1.0   \n",
            "4  What information must be included in the EU de...    True   1.0   \n",
            "\n",
            "                                       retrieved_ids  \\\n",
            "0  [0647e8da-06dc-418d-a5db-7d51468ae3de, 358f7e5...   \n",
            "1  [0647e8da-06dc-418d-a5db-7d51468ae3de, 358f7e5...   \n",
            "2  [096bff58-c010-431a-a0b9-b8661bd551b4, 4af04c0...   \n",
            "3  [096bff58-c010-431a-a0b9-b8661bd551b4, 3b0c926...   \n",
            "4  [bb37130f-2f53-453d-bb06-f47baded20c7, a4d092c...   \n",
            "\n",
            "                             expected_ids  \n",
            "0  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "1  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "2  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "3  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "4  [bb37130f-2f53-453d-bb06-f47baded20c7]  \n"
          ]
        }
      ],
      "source": [
        "te3_results: List[EvaluationResult] = te3_openai_evaluator.evaluation_results\n",
        "\n",
        "logger.info(f\"OpenAI model hit rate: {te3_openai_evaluator.hit_rate}\")\n",
        "logger.info(f\"OpenAI model MRR: {te3_openai_evaluator.mrr}\")\n",
        "\n",
        "te3_report = te3_openai_evaluator.generate_evaluation_report()\n",
        "print(te3_report.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "kkyW90TCxx_i"
      },
      "outputs": [],
      "source": [
        "# te3_results_df = pd.DataFrame(te3_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MscVRdNCylJ-",
        "outputId": "b3e8e0c2-11e3-4bfa-cea2-81c08cbbfcc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9870967741935484"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "te3_hit_rate = te3_report[\"is_hit\"].mean()\n",
        "te3_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ra-mh0L96dQ"
      },
      "source": [
        "### `Snowflake/snowflake-arctic-embed-m` (base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEskxwvFypHe",
        "outputId": "16597843-ef31-4899-cd5b-b67b24b0e552"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n",
            "/root/.cache/pypoetry/virtualenvs/fine-tuning-embedding-models-XvMgmHVc-py3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "\u001b[32m2024-09-19 01:31:10.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mPreparing vector store and retriever.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:11.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mRetriever prepared.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:11.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mStarting evaluation of all questions.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd3fdafe1394533a8e360a28f042b1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating model:   0%|          | 0/310 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:16.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mEvaluation of all questions completed.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_hit_rate\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mComputed hit rate: 0.5516129032258065\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_mean_reciprocal_rank\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mComputed Mean Reciprocal Rank (MRR): 0.3795698924731183\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mModel evaluation complete. Hit Rate: 0.5516129032258065, MRR: 0.3795698924731183\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-m\")\n",
        "arctic_evaluator = Evaluator(test_dataset, huggingface_embeddings, top_k=5)\n",
        "arctic_evaluator.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KlKgiXTWzMTg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:16.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mPre-trained Arctic model hit rate: 0.5516129032258065\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mPre-trained Arctic model MRR: 0.3795698924731183\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mGenerating evaluation report.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:16.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mEvaluation report generated.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            question_id  \\\n",
            "0  ee57e704-11a2-494e-a23e-529d91141a5b   \n",
            "1  7b478e5a-3991-46f7-9935-726a76ee7b3f   \n",
            "2  9867205c-a82f-49f4-8fd5-713ab8d8bf14   \n",
            "3  682c1384-2df1-4788-896a-45629b573a34   \n",
            "4  9c287439-c95d-4d88-b82c-27ed2833a61d   \n",
            "\n",
            "                                            question  is_hit  rank  \\\n",
            "0  How does the size of the provider impact the c...   False   NaN   \n",
            "1  What are the simplified ways of compliance for...   False   NaN   \n",
            "2  How can AI systems be designed to ensure equit...   False   NaN   \n",
            "3  What ethical considerations should be taken in...   False   NaN   \n",
            "4  What information must be included in the EU de...   False   NaN   \n",
            "\n",
            "                                       retrieved_ids  \\\n",
            "0  [e1e04ed1-5736-4de0-ae9d-8ab290a50f74, 694b37a...   \n",
            "1  [e1e04ed1-5736-4de0-ae9d-8ab290a50f74, 5ee2854...   \n",
            "2  [e1e04ed1-5736-4de0-ae9d-8ab290a50f74, ddc2e1f...   \n",
            "3  [e1e04ed1-5736-4de0-ae9d-8ab290a50f74, 5ee2854...   \n",
            "4  [e1e04ed1-5736-4de0-ae9d-8ab290a50f74, 5ee2854...   \n",
            "\n",
            "                             expected_ids  \n",
            "0  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "1  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "2  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "3  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "4  [bb37130f-2f53-453d-bb06-f47baded20c7]  \n"
          ]
        }
      ],
      "source": [
        "# arctic_embed_m_results_df = pd.DataFrame(arctic_embed_m_results)\n",
        "from typing import List\n",
        "\n",
        "arctic_results: List[EvaluationResult] = arctic_evaluator.evaluation_results\n",
        "logger.info(f\"Pre-trained Arctic model hit rate: {arctic_evaluator.hit_rate}\")\n",
        "logger.info(f\"Pre-trained Arctic model MRR: {arctic_evaluator.mrr}\")\n",
        "\n",
        "arctic_report = arctic_evaluator.generate_evaluation_report()\n",
        "print(arctic_report.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV5vJWrJzOhc",
        "outputId": "a5852dcc-42f3-4021-b1c7-c6fbaf62e358"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5516129032258065"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# arctic_embed_m_hit_rate = arctic_embed_m_results_df[\"is_hit\"].mean()\n",
        "# arctic_embed_m_hit_rate\n",
        "\n",
        "arctic_embed_m_hit_rate=arctic_report[\"is_hit\"].mean()\n",
        "arctic_embed_m_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcR3-0s19_lu"
      },
      "source": [
        "### `Snowflake/snowflake-arctic-embed-m` (fine-tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilse1LduzP1i",
        "outputId": "37a4d9c1-b01b-4654-8bb4-1571e3b9108e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n",
            "Some weights of BertModel were not initialized from the model checkpoint at finetuned_arctic and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2024-09-19 01:31:17.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mPreparing vector store and retriever.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:18.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_retriever\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mRetriever prepared.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:18.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mStarting evaluation of all questions.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f86dea5a5eb547e585dd9b8763072766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating model:   0%|          | 0/310 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:23.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_all_questions\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mEvaluation of all questions completed.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:23.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_hit_rate\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mComputed hit rate: 0.9967741935483871\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:23.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_mean_reciprocal_rank\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mComputed Mean Reciprocal Rank (MRR): 0.9748387096774194\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:23.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mModel evaluation complete. Hit Rate: 0.9967741935483871, MRR: 0.9748387096774194\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "finetune_embeddings = HuggingFaceEmbeddings(model_name=finetuned_model_output_path)\n",
        "finetune_evaluator = Evaluator(test_dataset, finetune_embeddings, top_k=5)\n",
        "finetune_evaluator.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "xxhZPqkNzZlh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:24.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mFine-tuned Arctic model hit rate: 0.9967741935483871\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mFine-tuned Arctic model MRR: 0.9748387096774194\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mGenerating evaluation report.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_evaluation_report\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mEvaluation report generated.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mGenerated evaluation report for fine-tuned model\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            question_id  \\\n",
            "0  ee57e704-11a2-494e-a23e-529d91141a5b   \n",
            "1  7b478e5a-3991-46f7-9935-726a76ee7b3f   \n",
            "2  9867205c-a82f-49f4-8fd5-713ab8d8bf14   \n",
            "3  682c1384-2df1-4788-896a-45629b573a34   \n",
            "4  9c287439-c95d-4d88-b82c-27ed2833a61d   \n",
            "\n",
            "                                            question  is_hit  rank  \\\n",
            "0  How does the size of the provider impact the c...    True   1.0   \n",
            "1  What are the simplified ways of compliance for...    True   1.0   \n",
            "2  How can AI systems be designed to ensure equit...    True   1.0   \n",
            "3  What ethical considerations should be taken in...    True   1.0   \n",
            "4  What information must be included in the EU de...    True   1.0   \n",
            "\n",
            "                                       retrieved_ids  \\\n",
            "0  [0647e8da-06dc-418d-a5db-7d51468ae3de, 358f7e5...   \n",
            "1  [0647e8da-06dc-418d-a5db-7d51468ae3de, a401596...   \n",
            "2  [096bff58-c010-431a-a0b9-b8661bd551b4, 4af04c0...   \n",
            "3  [096bff58-c010-431a-a0b9-b8661bd551b4, 273b51c...   \n",
            "4  [bb37130f-2f53-453d-bb06-f47baded20c7, a4d092c...   \n",
            "\n",
            "                             expected_ids  \n",
            "0  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "1  [0647e8da-06dc-418d-a5db-7d51468ae3de]  \n",
            "2  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "3  [096bff58-c010-431a-a0b9-b8661bd551b4]  \n",
            "4  [bb37130f-2f53-453d-bb06-f47baded20c7]  \n"
          ]
        }
      ],
      "source": [
        "# finetune_results_df = pd.DataFrame(finetune_results)\n",
        "finetune_results = finetune_evaluator.evaluation_results\n",
        "logger.info(f\"Fine-tuned Arctic model hit rate: {finetune_evaluator.hit_rate}\")\n",
        "logger.info(f\"Fine-tuned Arctic model MRR: {finetune_evaluator.mrr}\")\n",
        "\n",
        "finetune_report = finetune_evaluator.generate_evaluation_report()\n",
        "logger.info(\"Generated evaluation report for fine-tuned model\")\n",
        "print(finetune_report.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4thAK2BXzaj6",
        "outputId": "e5477f9b-882f-4b8d-c119-1edc042e0814"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9967741935483871"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finetune_hit_rate = finetune_results_df[\"is_hit\"].mean()\n",
        "# finetune_hit_rate\n",
        "finetune_hit_rate = finetune_report[\"is_hit\"].mean()\n",
        "finetune_hit_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2024-09-19 01:31:24.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_evaluations\u001b[0m:\u001b[36m181\u001b[0m - \u001b[1mStarting comparison of evaluation results.\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_evaluations\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mComputed metrics for OpenAI Embeddings - Hit Rate: 0.9870967741935484, MRR: 0.9381182795698925\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_evaluations\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mComputed metrics for Pre-trained Arctic Model - Hit Rate: 0.5516129032258065, MRR: 0.3795698924731183\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_evaluations\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mComputed metrics for Fine-tuned Arctic Model - Hit Rate: 0.9967741935483871, MRR: 0.9748387096774194\u001b[0m\n",
            "\u001b[32m2024-09-19 01:31:24.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_evaluations\u001b[0m:\u001b[36m216\u001b[0m - \u001b[1mComparison DataFrame created.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison of Evaluation Metrics:\n",
            "                 model_name  hit_rate       mrr  total_questions\n",
            "0         OpenAI Embeddings  0.987097  0.938118              310\n",
            "1  Pre-trained Arctic Model  0.551613  0.379570              310\n",
            "2   Fine-tuned Arctic Model  0.996774  0.974839              310\n"
          ]
        }
      ],
      "source": [
        "evaluation_data = [\n",
        "    (\"OpenAI Embeddings\", te3_results),\n",
        "    (\"Pre-trained Arctic Model\", arctic_results),\n",
        "    (\"Fine-tuned Arctic Model\", finetune_results),\n",
        "]\n",
        "\n",
        "# Generate comparison report\n",
        "comparison_df = Evaluator.compare_evaluations(evaluation_data)\n",
        "print(\"Comparison of Evaluation Metrics:\")\n",
        "print(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pR0Ug9C9odh"
      },
      "source": [
        "# ðŸ¤ Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iegFM209mBk3"
      },
      "source": [
        "## Task 1: Vibe Checking the RAG Pipeline\n",
        "\n",
        "We're going to use our RAG pipeline to vibe check on some common phrases now that we've modified it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzg0AA5krgR4"
      },
      "source": [
        "### Creating New Chunks\n",
        "\n",
        "In order to try and evaluate our system more fairly, let's create new chunks that we will use to create our Vector Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwQ2_LqNr0Tw"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 600,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "training_documents = text_splitter.split_documents(training_documents_loaded.load())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIdxahHXpP-c"
      },
      "source": [
        "### Base Chain\n",
        "\n",
        "We'll start by constructing our base chain, which will use the untrained retrieval model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOsxIXpNpWC2"
      },
      "source": [
        "#### R - Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azIGIKYfmNCT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "base_vectorstore = FAISS.from_documents(training_documents, huggingface_embeddings)\n",
        "base_retriever = base_vectorstore.as_retriever(search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-1nVZ0KpX5N"
      },
      "source": [
        "#### A - Augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G10Fr-aKojeA"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and a question, you must answer the question. If you do not know the answer, you must state that you do not know.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euq6RQEopZvD"
      },
      "source": [
        "#### G - Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-mfbbrypMHG"
      },
      "outputs": [],
      "source": [
        "rag_llm =  ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2p4mnUpbYY"
      },
      "source": [
        "#### RAG - LCEL RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssuR-LaboyGq"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "\n",
        "base_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt_template | rag_llm | StrOutputParser(), \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "emm6WbB9pfKt",
        "outputId": "846cc38f-48ef-4fab-c8d0-0de81756a7f8"
      },
      "outputs": [],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"Why does the EU want to regulate AI?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mUOrd0OBprAq",
        "outputId": "ddb07442-cb0f-47ce-9b7d-38d982ee9a8a"
      },
      "outputs": [],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"What are the codes of practice?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OnfuFl59py7I",
        "outputId": "12e9e015-e855-4f36-a3b7-0b5d0e8ac887"
      },
      "outputs": [],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"How many parameters is too many parameters?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "-NmqwHBDqTZ8",
        "outputId": "bc9979cf-adc8-4469-f3ba-a3e72e249b74"
      },
      "outputs": [],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"What is an emotion recognition system and why is it important?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqNS0UJAp3lC"
      },
      "source": [
        "### Fine-tuned Embedding Model\n",
        "\n",
        "Now let's rebuild our RAG chain with the Fine-tuned model - the only component we need to change is our `FAISS` vectorstore!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihO7tP6mqATy"
      },
      "outputs": [],
      "source": [
        "finetune_vectorstore = FAISS.from_documents(training_documents, finetune_embeddings)\n",
        "finetune_retriever = finetune_vectorstore.as_retriever(search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_cIFvWzqKGY"
      },
      "outputs": [],
      "source": [
        "finetune_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | finetune_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt_template | rag_llm | StrOutputParser(), \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "OJmRHJF2qNgj",
        "outputId": "42643a90-fe61-41c0-cc48-66ee9c7ccbc9"
      },
      "outputs": [],
      "source": [
        "finetune_rag_chain.invoke({\"question\" : \"Why does the EU want to regulate AI?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "EnK-c2ugqPPh",
        "outputId": "78ade357-0f1d-4bc6-dbc5-eb8cc65a9e31"
      },
      "outputs": [],
      "source": [
        "finetune_rag_chain.invoke({\"question\" : \"What are the codes of practice?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "83hssg1AWozc",
        "outputId": "aaa3681a-9ef7-4ff3-aae2-d796838a3bc5"
      },
      "outputs": [],
      "source": [
        "finetune_rag_chain.invoke({\"question\" : \"How many parameters is too many parameters?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "rsHmGeFbqRET",
        "outputId": "af611488-fc3d-4a55-ca2f-a53fd9fb9c2f"
      },
      "outputs": [],
      "source": [
        "finetune_rag_chain.invoke({\"question\" : \"What is an emotion recognition system and why is it important?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDgD8seY_I3W"
      },
      "source": [
        "#####â“Question #2:\n",
        "\n",
        "Which LCEL RAG Chain do you think answered the questions better, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCbq1sZArIx4"
      },
      "source": [
        "## Task 2: RAGAS Evaluation\n",
        "\n",
        "It's great to have some idea of how our system is doing based on vibe-checks, but let's use RAGAS to provide more insight info. on how things are improving!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FNscBsPdm3p"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wZzCz2mszM5"
      },
      "source": [
        "### RAGAS Synthetic Testset Generation\n",
        "\n",
        "First things first, we need to generate some data to test our model on.\n",
        "\n",
        "Let's use our test data that we created before as a base!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKdQYQqps97f"
      },
      "outputs": [],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tHo-ZcDtGSK"
      },
      "outputs": [],
      "source": [
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "67f8426ec3564bfc92eedc9735650b43",
            "677c60bfb37043cabc0b139a71959f7d",
            "aaef0a2c3ffd4fb6ac3b1a2f0988c46f",
            "4cd051b46ada4e12950cfc637d69cf8f",
            "d5c2492ca7a54489b675fc0425fe8b77",
            "be8b1994a4ae4c3eac97c4cc833f2b37",
            "79d61a9df892478daecb39655f3dee74",
            "76ea9db5e39b4758814e2dd704202716",
            "aada88f29776436996ea7018872c7098",
            "d9e0849597ca44cd92fb299737d0452b",
            "1215cebf146c41aabe62a395e29ca820",
            "fcd88593e3544b69b842ccf42080cd2c",
            "390d2efe4b6c44b2890e621e9e28298c",
            "3f9cb2759a084fdfbf2adb1804be0123",
            "6fca89f5ecbe416893f4c5da93a9315b",
            "237958ae659e4a0fbb9aa034bebfa6ab",
            "4bb635c7a03b4606b6ef793266c4c72a",
            "116c66011e0c48e6bb0943056652595f",
            "a9016a279c054677bc7b7aa12175b50a",
            "32a22903200f469fa3240f95833ea0ab",
            "acb585b50b724a8c86ec76e6c18ad850",
            "9de3c41e83f241b1a938081db44d6662"
          ]
        },
        "id": "YNjJsBOktLPT",
        "outputId": "ac88dd67-d618-4166-d57c-940e14e7b86b"
      },
      "outputs": [],
      "source": [
        "testset = generator.generate_with_langchain_docs(test_split_documents, test_size=20, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "u7z2qoDJvz_2",
        "outputId": "5136a3fc-905e-4751-c476-3a67a8f938d1"
      },
      "outputs": [],
      "source": [
        "testset.to_pandas().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBS7yLmwHo8"
      },
      "source": [
        "### Generating Answer Datasets\n",
        "\n",
        "For each of our pipelines, let's generate answers to these questions!\n",
        "\n",
        "Once we have our: Questions, Answers, Contexts, Ground Truths we can move on to evaluating our datasets!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDxhIdZFwnyK"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def generate_answers(chain, testset):\n",
        "  answers = []\n",
        "  contexts = []\n",
        "  questions = testset.to_pandas()[\"question\"].values.tolist()\n",
        "  ground_truths = testset.to_pandas()[\"ground_truth\"].values.tolist()\n",
        "\n",
        "  for question in tqdm(questions):\n",
        "    answer = chain.invoke({\"question\" : question})\n",
        "    answers.append(answer[\"response\"])\n",
        "    contexts.append([context.page_content for context in answer[\"context\"]])\n",
        "\n",
        "  return Dataset.from_dict({\n",
        "      \"question\" : questions,\n",
        "      \"answer\" : answers,\n",
        "      \"contexts\" : contexts,\n",
        "      \"ground_truth\" : ground_truths\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K64AC_PFyuM9",
        "outputId": "3ddd8c53-9bb1-43c3-98ab-8ea1d297b788"
      },
      "outputs": [],
      "source": [
        "base_dataset = generate_answers(base_rag_chain, testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABwQzmJuzB5J",
        "outputId": "acdfdbba-fc78-4b90-d103-48f39c1a60a4"
      },
      "outputs": [],
      "source": [
        "finetune_dataset = generate_answers(finetune_rag_chain, testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2rN2lmvHeq"
      },
      "source": [
        "### Evaluating Using the Test Set\n",
        "\n",
        "Now that we have a test set - it's time to evaluate our pipelines with it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv1XatkXvOaL"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04680a1c217640349cc5db3b73013a37",
            "7324e4f685ac4b038abf3bfdca3ba1b8",
            "72fb3d084d594aca94ee9271277de633",
            "66d27c3a4cdd49309ac724a9e75a1c1b",
            "dc39575014e34d3d9f83b05c0144996d",
            "1e0162a982e5496cb7cb96c8a1d93d58",
            "6251ec4e341a4481a29ee5b802a4c382",
            "fd9fa542c30b4aeab1779a08399cb003",
            "f7ef34d24d564ae2b558e3fddcee8ba4",
            "cd1500565cea46c092c682f1287c11e7",
            "933edd8317124492ab9d4e787ce31cac"
          ]
        },
        "id": "eKrPx5Hsz2Vp",
        "outputId": "9c619024-db21-407a-b6cb-507462a2bcbe"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "\n",
        "result = evaluate(\n",
        "    base_dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhkCw25F1V_l",
        "outputId": "6d7b2c18-38f4-4074-f134-f0ae9c3b3a00"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "YhkPzbz60_Rq",
        "outputId": "7b61a434-9a7b-4f7a-cda8-8518394423b9"
      },
      "outputs": [],
      "source": [
        "result.to_pandas().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7242ab4f7dc64b16b849be47fa482198",
            "465cb463ca784fb09ffdf761c9de5cce",
            "ded7e9c44db944f88b88618c528f38d5",
            "60f74d1bbfd14733a86e70bea5df8def",
            "4e31ce8c663f4c8c8b2c6e14efa53522",
            "bfd322c3ecbf476bb07a1229ce78354e",
            "9e9ad9be36984bb689184aa020abf5cd",
            "6562eb8164714831a3a6307aae78d36f",
            "d82c085d8f1b45fabf77e458a002201a",
            "2741368826e14dccb41889cff2de5452",
            "012c733b007541d680804c4e7ff0d8e6"
          ]
        },
        "id": "pG3Cdbg11aP6",
        "outputId": "c52a0b71-24f1-4453-e0cc-494b66670634"
      },
      "outputs": [],
      "source": [
        "result = evaluate(\n",
        "    finetune_dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weKKUo1n1lva",
        "outputId": "1c4f0cff-4480-4364-cced-b4655366dd52"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "MRdqp-Jb2KI3",
        "outputId": "a2a507b7-aefc-4af0-e733-757c4bec1c4a"
      },
      "outputs": [],
      "source": [
        "result.to_pandas().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-aKOB1m-Bi8"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #3:\n",
        "\n",
        "Discuss changes that you'd make to this pipeline based on the performance improvements that you see with RAGAS and the fine-tuning.\n",
        "\n",
        "Come up with 3 changes, and then we'll discuss these options as a group!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCgzuZd-TTs"
      },
      "source": [
        "1. ...\n",
        "2. ...\n",
        "3. ..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fine-tuning-embedding-models-XvMgmHVc-py3.11",
      "language": "python",
      "name": "fine-tuning-embedding-models-xvmgmhvc-py3.11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012c733b007541d680804c4e7ff0d8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a08dd4d70d4432b0fab7c91dfd4952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31f7c076ebb94ab18771c89508c011a8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb1aaa6522d6443aa054f5096d578259",
            "value": 231508
          }
        },
        "045466897c2a4ea6bab6af0d846d1c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe3c123606f4a889604c381daf69a0c",
            "max": 107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ff8349859a64156999928803f4e1f13",
            "value": 107
          }
        },
        "04680a1c217640349cc5db3b73013a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7324e4f685ac4b038abf3bfdca3ba1b8",
              "IPY_MODEL_72fb3d084d594aca94ee9271277de633",
              "IPY_MODEL_66d27c3a4cdd49309ac724a9e75a1c1b"
            ],
            "layout": "IPY_MODEL_dc39575014e34d3d9f83b05c0144996d"
          }
        },
        "057a9c59128147dfa1e5b7773727a290": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a002a67a7c461d868e8493fb9dd9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad9b226b0d54e84af3589f921cb2702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7695d067dd0542a1988c1bbdfdfce6c8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fc62cd62e1824fa69d0a10a4bab2984f",
            "value": "â€‡695/695â€‡[00:00&lt;00:00,â€‡53.2kB/s]"
          }
        },
        "0ecafb90cca943f6a1ba1b29c1b8d997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab848092a25549e79d67666692477e76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f55a8ca4877243929e4295dfd770c54b",
            "value": 1
          }
        },
        "116c66011e0c48e6bb0943056652595f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1215cebf146c41aabe62a395e29ca820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1407b2bad808412d957df561b72ea955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fb4080c5c34c7bbaa796405f50918a",
              "IPY_MODEL_8e480911c0f64979b24b84ef51470b3f",
              "IPY_MODEL_6572440d16e54c16a24596560d42292c"
            ],
            "layout": "IPY_MODEL_a15e3ac1dfea433ab8b18ea574f883a4"
          }
        },
        "16669e326c7b46dc8ee81a0b68a71dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f60b0ec5e74f1c9e3b415e4bb3a65f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1afa28891b86457c829dcb47841bb1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfcd54f2ca7b47f38a48c28b3070b0f2",
              "IPY_MODEL_60f065e48c324ae09bc3b578086c6c4d",
              "IPY_MODEL_c6f8b13d889c4703b9741a9b771459f0"
            ],
            "layout": "IPY_MODEL_29dca68a060a4f65af0f18e74c6cac90"
          }
        },
        "1db2b8edfc8642d1b77d6cf924a6ffe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddc9dcb8b7f04da68112002b5dd30d7f",
              "IPY_MODEL_e479eb316e8b43df95fdf7a30e776335",
              "IPY_MODEL_1e21125d040944dca0cf73c6ceb94121"
            ],
            "layout": "IPY_MODEL_628a5cacf5c84492a5a546951518043f"
          }
        },
        "1e0162a982e5496cb7cb96c8a1d93d58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e21125d040944dca0cf73c6ceb94121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ed37211fb542849659e31f6e063a5f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b466843397bc4f8589a31e119e8f9f1d",
            "value": "â€‡1.38k/1.38kâ€‡[00:00&lt;00:00,â€‡114kB/s]"
          }
        },
        "1f8ec322392d46c9ac07b7611d9cefc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fac3b522972494ab14f906f949f415d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fed5d0ecba541818a82ef568ee1ca07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23344114789940699592e8ef06cc07de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "237958ae659e4a0fbb9aa034bebfa6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254824b708714e9387ca8dadb27fd6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25e7849a677947ed87bc2013ad272193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f05a9747d74fffa75740e092f9b5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057a9c59128147dfa1e5b7773727a290",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_55a69fb9aea44d60b9243640e8da2fd8",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "2741368826e14dccb41889cff2de5452": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29dca68a060a4f65af0f18e74c6cac90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2dfa2d63d94319ada0439a8c72a79b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4d00a504214cdf966dc92743233add": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e123d8c9de447aca17da3b999028aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed43f8b5f2148f19c25c1a7d5273013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6129febcb72c4894894d5ef3f3122fee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d93df488629743969aec1bd287abc9e1",
            "value": "sentence_bert_config.json:â€‡100%"
          }
        },
        "303ecf4e89b74978a6b595f8b0329068": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304ffd0931674f83bcebfcc8b661f70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f7c076ebb94ab18771c89508c011a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a22903200f469fa3240f95833ea0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "356bd62aee954525b87ca3d4ea4c5b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "359b4bf7e3cd4b2e930226c51bd2b782": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abd88c222bc04abd9879d0436ab4c76f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8f00e82313146299cb6d9f364c4bb91",
            "value": "â€‡738/738â€‡[00:00&lt;00:00,â€‡60.5kB/s]"
          }
        },
        "36f1c10f4e1f43a2b661fcf1a91428ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390d2efe4b6c44b2890e621e9e28298c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb635c7a03b4606b6ef793266c4c72a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_116c66011e0c48e6bb0943056652595f",
            "value": "Generating:â€‡100%"
          }
        },
        "3b55813b7f5749a4a2781e0ec2ad17d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec0b9283e3e41a7814eb2077cd0267a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f9800b8187e94c4eb5695773f765bae4",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "3badcc68c9804879b972530f284134c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9cb2759a084fdfbf2adb1804be0123": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9016a279c054677bc7b7aa12175b50a",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a22903200f469fa3240f95833ea0ab",
            "value": 20
          }
        },
        "411a7c1e888e4b46a3353c88f77c1168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c56b792407f4354a7071a201d696c6b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4a2159573f0542b3b4f70bb431a3273b",
            "value": "â€‡436M/436Mâ€‡[00:01&lt;00:00,â€‡298MB/s]"
          }
        },
        "453edb491d2b4423b17f76b91e22eb11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4570a92958c541cfa6f977bb7f157f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4637102470d54841997dd90f396a1bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ed56c3f5c94cf09ecb27a6f920d119",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_956c675d7c4b46339fad4331a1de3ea3",
            "value": "1_Pooling/config.json:â€‡100%"
          }
        },
        "465cb463ca784fb09ffdf761c9de5cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd322c3ecbf476bb07a1229ce78354e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e9ad9be36984bb689184aa020abf5cd",
            "value": "Evaluating:â€‡100%"
          }
        },
        "472e5154b9ee40e0beaa9cd384c0c41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a2159573f0542b3b4f70bb431a3273b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb635c7a03b4606b6ef793266c4c72a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc8914cbc424a75a8d9e39e383aa38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd051b46ada4e12950cfc637d69cf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e0849597ca44cd92fb299737d0452b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1215cebf146c41aabe62a395e29ca820",
            "value": "â€‡100/100â€‡[00:04&lt;00:00,â€‡15.24it/s]"
          }
        },
        "4e31ce8c663f4c8c8b2c6e14efa53522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe3c123606f4a889604c381daf69a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff8349859a64156999928803f4e1f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53f4e76eb46643f79f1a739468ad37f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a69fb9aea44d60b9243640e8da2fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c56b792407f4354a7071a201d696c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7bdcc9e64f44d29385b053bda75132": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e02dcc53a3e4c08ade7510f577cce82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec0b9283e3e41a7814eb2077cd0267a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602e85c144f848be98102d8a78f910b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f065e48c324ae09bc3b578086c6c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_453edb491d2b4423b17f76b91e22eb11",
            "max": 84616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_472e5154b9ee40e0beaa9cd384c0c41f",
            "value": 84616
          }
        },
        "60f74d1bbfd14733a86e70bea5df8def": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2741368826e14dccb41889cff2de5452",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_012c733b007541d680804c4e7ff0d8e6",
            "value": "â€‡40/40â€‡[00:13&lt;00:00,â€‡â€‡1.80it/s]"
          }
        },
        "6129febcb72c4894894d5ef3f3122fee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6251ec4e341a4481a29ee5b802a4c382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "628a5cacf5c84492a5a546951518043f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b4bdcd3fcd4bd588d379fe9f057c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32f1b5633cb49d087871c0635b1896b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b52e8ddb07af4bc69d3862e97775d48c",
            "value": "â€‡107/107â€‡[00:00&lt;00:00,â€‡8.37kB/s]"
          }
        },
        "63ed56c3f5c94cf09ecb27a6f920d119": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f6a012161148c58f4af19ceb05c814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6562eb8164714831a3a6307aae78d36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6572440d16e54c16a24596560d42292c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb7aeece0e694331ad932ac4f8edb4a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e5d73b122a9d416a95ff302962acf82d",
            "value": "â€‡712k/712kâ€‡[00:00&lt;00:00,â€‡2.94MB/s]"
          }
        },
        "668422e9b4764365b722254f4b70089f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2dfa2d63d94319ada0439a8c72a79b",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff51d7d6308a4d61a43cce32dd7c0c0b",
            "value": 349
          }
        },
        "66d27c3a4cdd49309ac724a9e75a1c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd1500565cea46c092c682f1287c11e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_933edd8317124492ab9d4e787ce31cac",
            "value": "â€‡40/40â€‡[03:00&lt;00:00,â€‡48.99s/it]"
          }
        },
        "677c60bfb37043cabc0b139a71959f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be8b1994a4ae4c3eac97c4cc833f2b37",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_79d61a9df892478daecb39655f3dee74",
            "value": "embeddingâ€‡nodes:â€‡100%"
          }
        },
        "67f8426ec3564bfc92eedc9735650b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_677c60bfb37043cabc0b139a71959f7d",
              "IPY_MODEL_aaef0a2c3ffd4fb6ac3b1a2f0988c46f",
              "IPY_MODEL_4cd051b46ada4e12950cfc637d69cf8f"
            ],
            "layout": "IPY_MODEL_d5c2492ca7a54489b675fc0425fe8b77"
          }
        },
        "6851a1705d8f4ff58503bdb0a7c26092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16669e326c7b46dc8ee81a0b68a71dd5",
            "max": 435588776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_254824b708714e9387ca8dadb27fd6ab",
            "value": 435588776
          }
        },
        "6b189ea0062644639aeff3a214c87320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7bce82918a4464b7df47264e77d171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8627e76e196e488d97b61aec846d41ca",
            "max": 252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e23f008b0b4399a75d8784ced71e9e",
            "value": 252
          }
        },
        "6fca89f5ecbe416893f4c5da93a9315b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb585b50b724a8c86ec76e6c18ad850",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9de3c41e83f241b1a938081db44d6662",
            "value": "â€‡20/20â€‡[01:08&lt;00:00,â€‡â€‡8.94s/it]"
          }
        },
        "7242ab4f7dc64b16b849be47fa482198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_465cb463ca784fb09ffdf761c9de5cce",
              "IPY_MODEL_ded7e9c44db944f88b88618c528f38d5",
              "IPY_MODEL_60f74d1bbfd14733a86e70bea5df8def"
            ],
            "layout": "IPY_MODEL_4e31ce8c663f4c8c8b2c6e14efa53522"
          }
        },
        "72fb3d084d594aca94ee9271277de633": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9fa542c30b4aeab1779a08399cb003",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7ef34d24d564ae2b558e3fddcee8ba4",
            "value": 40
          }
        },
        "7324e4f685ac4b038abf3bfdca3ba1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e0162a982e5496cb7cb96c8a1d93d58",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6251ec4e341a4481a29ee5b802a4c382",
            "value": "Evaluating:â€‡100%"
          }
        },
        "74efec7e0de34089803c12fb42d6f6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7695d067dd0542a1988c1bbdfdfce6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ea9db5e39b4758814e2dd704202716": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772df792d4c04c0884f114525c6f7b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7853da5ffbbc4308a91a243536fb1feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d61a9df892478daecb39655f3dee74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e523c3059444b4a130de6cc0791942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87f72bde86c4eb7b5df7aa546cd69af",
              "IPY_MODEL_df04925f87514c9696dc8a08519bc818",
              "IPY_MODEL_359b4bf7e3cd4b2e930226c51bd2b782"
            ],
            "layout": "IPY_MODEL_6b189ea0062644639aeff3a214c87320"
          }
        },
        "85591cbcaa084d4d9b9cddbfb3a7338c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303ecf4e89b74978a6b595f8b0329068",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_304ffd0931674f83bcebfcc8b661f70e",
            "value": "â€‡252/252â€‡[00:00&lt;00:00,â€‡20.3kB/s]"
          }
        },
        "85ed37211fb542849659e31f6e063a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8627e76e196e488d97b61aec846d41ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ae8c267ef4434596d1b4304ed71607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e480911c0f64979b24b84ef51470b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8ec322392d46c9ac07b7611d9cefc8",
            "max": 711649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63f6a012161148c58f4af19ceb05c814",
            "value": 711649
          }
        },
        "933edd8317124492ab9d4e787ce31cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "956c675d7c4b46339fad4331a1de3ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9894dc1c8ffe4e8b9776ff87faa99d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed43f8b5f2148f19c25c1a7d5273013",
              "IPY_MODEL_045466897c2a4ea6bab6af0d846d1c08",
              "IPY_MODEL_62b4bdcd3fcd4bd588d379fe9f057c28"
            ],
            "layout": "IPY_MODEL_602e85c144f848be98102d8a78f910b3"
          }
        },
        "9ccf933a929d43858cb711111042eac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de3c41e83f241b1a938081db44d6662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9ad9be36984bb689184aa020abf5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee5b5f3855a474b9a66d0d555d84e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee9d4f56edb481e998f45a046edd336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a125b06e1a6b44cdbb08a9319e7b8ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15e3ac1dfea433ab8b18ea574f883a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71d010774274a579fe8814bd4083c68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73a34aeac884ef2ae8fe267e3451f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9016a279c054677bc7b7aa12175b50a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aada88f29776436996ea7018872c7098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaef0a2c3ffd4fb6ac3b1a2f0988c46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ea9db5e39b4758814e2dd704202716",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aada88f29776436996ea7018872c7098",
            "value": 100
          }
        },
        "ab848092a25549e79d67666692477e76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd88c222bc04abd9879d0436ab4c76f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf56378f5544d81b81fc7d0147f70c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b55813b7f5749a4a2781e0ec2ad17d9",
              "IPY_MODEL_c39e7c13fd914f729417b9017aa7f5b7",
              "IPY_MODEL_0ad9b226b0d54e84af3589f921cb2702"
            ],
            "layout": "IPY_MODEL_1fac3b522972494ab14f906f949f415d"
          }
        },
        "acb585b50b724a8c86ec76e6c18ad850": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada40c6433a243c3b106b9715439d31d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4f4c1b56a3411e8dfa7a542c0a5e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f05a9747d74fffa75740e092f9b5dc",
              "IPY_MODEL_03a08dd4d70d4432b0fab7c91dfd4952",
              "IPY_MODEL_ed03aa3ca0414671884c4adbf4b31a49"
            ],
            "layout": "IPY_MODEL_17f60b0ec5e74f1c9e3b415e4bb3a65f"
          }
        },
        "b125a269562941588c80175feabaf8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f953437353c245ddba2fe5d7d1b8ddac",
              "IPY_MODEL_6e7bce82918a4464b7df47264e77d171",
              "IPY_MODEL_85591cbcaa084d4d9b9cddbfb3a7338c"
            ],
            "layout": "IPY_MODEL_ada40c6433a243c3b106b9715439d31d"
          }
        },
        "b466843397bc4f8589a31e119e8f9f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e23f008b0b4399a75d8784ced71e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b52e8ddb07af4bc69d3862e97775d48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7dc02832fb24487a7173fe6d0cc577a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8f00e82313146299cb6d9f364c4bb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8b1994a4ae4c3eac97c4cc833f2b37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa68454ab7b44e095821820e1b732d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd322c3ecbf476bb07a1229ce78354e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfda4343a7ae48bd827e35540e5d5cee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39e7c13fd914f729417b9017aa7f5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc97ac6e5979415e9feb665ef7cc508b",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7dc02832fb24487a7173fe6d0cc577a",
            "value": 695
          }
        },
        "c536f9207bde42f3b51cb38e3659653e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a125b06e1a6b44cdbb08a9319e7b8ab4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25e7849a677947ed87bc2013ad272193",
            "value": "â€‡0/1â€‡[00:00&lt;?,â€‡?example/s]"
          }
        },
        "c6f8b13d889c4703b9741a9b771459f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71d010774274a579fe8814bd4083c68",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_53f4e76eb46643f79f1a739468ad37f6",
            "value": "â€‡84.6k/84.6kâ€‡[00:00&lt;00:00,â€‡5.78MB/s]"
          }
        },
        "c7fb4080c5c34c7bbaa796405f50918a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3badcc68c9804879b972530f284134c0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_356bd62aee954525b87ca3d4ea4c5b85",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "c8713888466944378baf79f547a3c704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c87f72bde86c4eb7b5df7aa546cd69af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ed03ee3cd647afbcf251ea0ea66838",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_23344114789940699592e8ef06cc07de",
            "value": "config.json:â€‡100%"
          }
        },
        "c9b54e153e4949639872750cf96f3622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec4a8844cc06408bbc9c53b0dace83d6",
              "IPY_MODEL_6851a1705d8f4ff58503bdb0a7c26092",
              "IPY_MODEL_411a7c1e888e4b46a3353c88f77c1168"
            ],
            "layout": "IPY_MODEL_5e02dcc53a3e4c08ade7510f577cce82"
          }
        },
        "cb7aeece0e694331ad932ac4f8edb4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc97ac6e5979415e9feb665ef7cc508b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1500565cea46c092c682f1287c11e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfcd54f2ca7b47f38a48c28b3070b0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a002a67a7c461d868e8493fb9dd9e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4cc8914cbc424a75a8d9e39e383aa38a",
            "value": "README.md:â€‡100%"
          }
        },
        "d03944eaa7c0402e8f950080c6086a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5c2492ca7a54489b675fc0425fe8b77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d82c085d8f1b45fabf77e458a002201a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d93df488629743969aec1bd287abc9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e0849597ca44cd92fb299737d0452b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc39575014e34d3d9f83b05c0144996d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc9dcb8b7f04da68112002b5dd30d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6ba9cdb70fb45aa8bb6a5d6cb7f5086",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e920c2ce9819473195e85dbc8dfdae87",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "de7dab41468340a080a93106f6e71816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ded7e9c44db944f88b88618c528f38d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6562eb8164714831a3a6307aae78d36f",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d82c085d8f1b45fabf77e458a002201a",
            "value": 40
          }
        },
        "df04925f87514c9696dc8a08519bc818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4d00a504214cdf966dc92743233add",
            "max": 738,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de7dab41468340a080a93106f6e71816",
            "value": 738
          }
        },
        "e32f1b5633cb49d087871c0635b1896b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e479eb316e8b43df95fdf7a30e776335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89ae8c267ef4434596d1b4304ed71607",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d03944eaa7c0402e8f950080c6086a45",
            "value": 1381
          }
        },
        "e51a3ed6a276432cb81a3b3485dc6147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5a932408e547f99ea5a882fc1630fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5d7bdcc9e64f44d29385b053bda75132",
            "value": "Computingâ€‡widgetâ€‡examples:â€‡â€‡â€‡0%"
          }
        },
        "e5d73b122a9d416a95ff302962acf82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6ba9cdb70fb45aa8bb6a5d6cb7f5086": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fc4c0a3c344e98808ff1d73115eefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e51a3ed6a276432cb81a3b3485dc6147",
              "IPY_MODEL_0ecafb90cca943f6a1ba1b29c1b8d997",
              "IPY_MODEL_c536f9207bde42f3b51cb38e3659653e"
            ],
            "layout": "IPY_MODEL_c8713888466944378baf79f547a3c704"
          }
        },
        "e920c2ce9819473195e85dbc8dfdae87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e99454f3c33942138596e5bb3330d191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1aaa6522d6443aa054f5096d578259": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec4a8844cc06408bbc9c53b0dace83d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfda4343a7ae48bd827e35540e5d5cee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_74efec7e0de34089803c12fb42d6f6e2",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "ed03aa3ca0414671884c4adbf4b31a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee5b5f3855a474b9a66d0d555d84e9e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0438fdc8c0c4799a08a8ba59fc77b66",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡16.8MB/s]"
          }
        },
        "ed5a932408e547f99ea5a882fc1630fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0c556991cf4e1c8f6ab941f3e71a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4637102470d54841997dd90f396a1bb1",
              "IPY_MODEL_fa2e5b619cce49d391e8838424cb51ad",
              "IPY_MODEL_f4a943bcd4e141dc8f275d67ba6ffbb2"
            ],
            "layout": "IPY_MODEL_1fed5d0ecba541818a82ef568ee1ca07"
          }
        },
        "ef7490f3fcdc49198cd387495ed379fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e99454f3c33942138596e5bb3330d191",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ee9d4f56edb481e998f45a046edd336",
            "value": "modules.json:â€‡100%"
          }
        },
        "f0438fdc8c0c4799a08a8ba59fc77b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a943bcd4e141dc8f275d67ba6ffbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e123d8c9de447aca17da3b999028aa4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ccf933a929d43858cb711111042eac7",
            "value": "â€‡296/296â€‡[00:00&lt;00:00,â€‡21.8kB/s]"
          }
        },
        "f55a8ca4877243929e4295dfd770c54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f64f0933cd8344e995e1cb450177d784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef7490f3fcdc49198cd387495ed379fc",
              "IPY_MODEL_668422e9b4764365b722254f4b70089f",
              "IPY_MODEL_fb794f8d73b44aafb923e9275907bbae"
            ],
            "layout": "IPY_MODEL_4570a92958c541cfa6f977bb7f157f1c"
          }
        },
        "f6ed03ee3cd647afbcf251ea0ea66838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ef34d24d564ae2b558e3fddcee8ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f953437353c245ddba2fe5d7d1b8ddac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73a34aeac884ef2ae8fe267e3451f2b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7853da5ffbbc4308a91a243536fb1feb",
            "value": "config_sentence_transformers.json:â€‡100%"
          }
        },
        "f9800b8187e94c4eb5695773f765bae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2e5b619cce49d391e8838424cb51ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa68454ab7b44e095821820e1b732d3",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff8395eefdeb4449a36a48e0787f495e",
            "value": 296
          }
        },
        "fb794f8d73b44aafb923e9275907bbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f1c10f4e1f43a2b661fcf1a91428ce",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_772df792d4c04c0884f114525c6f7b41",
            "value": "â€‡349/349â€‡[00:00&lt;00:00,â€‡18.3kB/s]"
          }
        },
        "fc62cd62e1824fa69d0a10a4bab2984f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcd88593e3544b69b842ccf42080cd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_390d2efe4b6c44b2890e621e9e28298c",
              "IPY_MODEL_3f9cb2759a084fdfbf2adb1804be0123",
              "IPY_MODEL_6fca89f5ecbe416893f4c5da93a9315b"
            ],
            "layout": "IPY_MODEL_237958ae659e4a0fbb9aa034bebfa6ab"
          }
        },
        "fd9fa542c30b4aeab1779a08399cb003": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff51d7d6308a4d61a43cce32dd7c0c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff8395eefdeb4449a36a48e0787f495e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
